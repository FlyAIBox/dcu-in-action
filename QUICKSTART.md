# ğŸš€ æµ·å…‰DCUåŠ é€Ÿå¡å®æˆ˜ - å¿«é€Ÿå¼€å§‹æŒ‡å—

æ¬¢è¿ä½¿ç”¨æµ·å…‰DCUåŠ é€Ÿå¡å®æˆ˜é¡¹ç›®ï¼æœ¬æŒ‡å—å°†å¸®åŠ©æ‚¨å¿«é€Ÿä¸Šæ‰‹ï¼Œä»ç¯å¢ƒé…ç½®åˆ°è¿è¡Œç¬¬ä¸€ä¸ªå¤§æ¨¡å‹åº”ç”¨ã€‚

## ğŸ“‹ å‰ç½®è¦æ±‚

### ç¡¬ä»¶è¦æ±‚
- **DCUè®¾å¤‡**: æµ·å…‰K100ã€K100-AIã€Z100Lç­‰
- **å†…å­˜**: æ¨è32GBä»¥ä¸Šç³»ç»Ÿå†…å­˜
- **å­˜å‚¨**: è‡³å°‘100GBå¯ç”¨ç£ç›˜ç©ºé—´
- **ç½‘ç»œ**: ç¨³å®šçš„äº’è”ç½‘è¿æ¥ï¼ˆç”¨äºä¸‹è½½æ¨¡å‹ï¼‰

### è½¯ä»¶è¦æ±‚
- **æ“ä½œç³»ç»Ÿ**: Ubuntu 20.04+ æˆ– CentOS 7.9+
- **DCUé©±åŠ¨**: DTK 25.04+
- **Docker**: 20.10+ (å¯é€‰ï¼Œæ¨è)
- **Python**: 3.8+ (å¦‚æœä¸ä½¿ç”¨Docker)

## ğŸ› ï¸ å®‰è£…æ–¹å¼

æˆ‘ä»¬æä¾›ä¸¤ç§å®‰è£…æ–¹å¼ï¼Œæ¨èä½¿ç”¨Dockeræ–¹å¼ä»¥è·å¾—æœ€ä½³ä½“éªŒã€‚

### æ–¹å¼1: Dockerå®‰è£… (æ¨è)

#### 1.1 å…‹éš†é¡¹ç›®
```bash
git clone https://github.com/hygon-technologies/dcu-in-action.git
cd dcu-in-action
```

#### 1.2 åˆå§‹åŒ–ç¯å¢ƒ
```bash
# ä½¿ç”¨Makefileå¿«é€Ÿè®¾ç½®
make setup

# æˆ–æ‰‹åŠ¨åˆ›å»ºç›®å½•
mkdir -p models datasets outputs logs
chmod +x scripts/setup/*.sh docker-entrypoint.sh
```

#### 1.3 æ„å»ºDockeré•œåƒ
```bash
# å¿«é€Ÿæ„å»º
make build

# æˆ–ä½¿ç”¨dockerå‘½ä»¤
docker build -t dcu-in-action:latest .
```

#### 1.4 å¯åŠ¨å¼€å‘ç¯å¢ƒ
```bash
# å¯åŠ¨ä¸»å®¹å™¨
make run

# æˆ–å¯åŠ¨æ‰€æœ‰æœåŠ¡
make run-all
```

#### 1.5 è¿›å…¥å®¹å™¨
```bash
# è¿›å…¥å¼€å‘å®¹å™¨
make shell

# æˆ–ç›´æ¥ä½¿ç”¨dockerå‘½ä»¤
docker exec -it dcu-dev-main bash
```

### æ–¹å¼2: æœ¬åœ°å®‰è£…

#### 2.1 å…‹éš†é¡¹ç›®
```bash
git clone https://github.com/hygon-technologies/dcu-in-action.git
cd dcu-in-action
```

#### 2.2 æ£€æŸ¥DCUç¯å¢ƒ
```bash
# è¿è¡Œç¯å¢ƒæ£€æŸ¥è„šæœ¬
bash scripts/setup/check_environment.sh
```

#### 2.3 å®‰è£…ä¾èµ–
```bash
# è‡ªåŠ¨å®‰è£…è„šæœ¬
bash scripts/setup/install_dependencies.sh

# æˆ–ä½¿ç”¨Makefile
make install

# æˆ–æ‰‹åŠ¨å®‰è£…
pip install -r requirements.txt
```

## ğŸƒâ€â™‚ï¸ å¿«é€ŸéªŒè¯

### 1. åŸºç¡€ç¯å¢ƒæµ‹è¯•
```bash
# æµ‹è¯•DCUç¯å¢ƒ
python examples/llm-inference/simple_test.py

# æˆ–ä½¿ç”¨Makefile
make test-dcu
```

æœŸæœ›è¾“å‡ºï¼š
```
ğŸ”„ å¼€å§‹DCUç¯å¢ƒæµ‹è¯•...
âœ… DCUè®¾å¤‡æ£€æµ‹æˆåŠŸ
âœ… PyTorch DCUæ”¯æŒæ­£å¸¸
âœ… åŸºç¡€è®¡ç®—æµ‹è¯•é€šè¿‡
âœ… æ··åˆç²¾åº¦æµ‹è¯•é€šè¿‡
ğŸ“Š æµ‹è¯•æŠ¥å‘Šå·²ä¿å­˜
```

### 2. DCUæ€§èƒ½ç›‘æ§
```bash
# å¯åŠ¨æ€§èƒ½ç›‘æ§
python scripts/utils/monitor_performance.py monitor

# æˆ–ä½¿ç”¨Makefile
make monitor-local
```

### 3. æ¨¡å‹æ¨ç†æµ‹è¯•
```bash
# ChatGLMæ¨ç†æµ‹è¯•
python examples/llm-inference/chatglm_inference.py --mode chat

# æˆ–åŸºå‡†æµ‹è¯•
python examples/llm-inference/chatglm_inference.py --mode benchmark
```

## ğŸ¯ æ ¸å¿ƒåŠŸèƒ½æ¼”ç¤º

### 1. å¤§æ¨¡å‹æ¨ç†

#### 1.1 ç®€å•æ¨ç†æµ‹è¯•
```bash
# å•æ¬¡æ¨ç†
python examples/llm-inference/chatglm_inference.py \
    --mode test \
    --prompt "ä»‹ç»ä¸€ä¸‹æµ·å…‰DCUçš„æŠ€æœ¯ä¼˜åŠ¿"
```

#### 1.2 äº¤äº’å¼å¯¹è¯
```bash
# å¯åŠ¨èŠå¤©æ¨¡å¼
python examples/llm-inference/chatglm_inference.py --mode chat
```

#### 1.3 é«˜æ€§èƒ½æ¨ç†æœåŠ¡
```bash
# å¯åŠ¨vLLMæ¨ç†æœåŠ¡
python examples/llm-inference/vllm_server.py \
    --mode server \
    --model "Qwen/Qwen-7B-Chat" \
    --host 0.0.0.0 \
    --port 8000
```

ç„¶åè®¿é—® http://localhost:8000/docs æŸ¥çœ‹APIæ–‡æ¡£

### 2. æ¨¡å‹è®­ç»ƒ

#### 2.1 åˆ›å»ºè®­ç»ƒæ•°æ®
```bash
# åˆ›å»ºç¤ºä¾‹æ•°æ®
python examples/llm-fine-tuning/lora_finetune.py --create_sample_data
```

#### 2.2 LoRAå¾®è°ƒ
```bash
# å¯åŠ¨LoRAå¾®è°ƒ
python examples/llm-fine-tuning/lora_finetune.py \
    --dataset_path ./data/sample_data.json \
    --output_dir ./outputs/lora-finetuned \
    --num_train_epochs 3 \
    --per_device_train_batch_size 4

# æˆ–ä½¿ç”¨Makefile
make train-lora
```

#### 2.3 å®Œæ•´æ¨¡å‹è®­ç»ƒ
```bash
# LLaMAæ¨¡å‹è®­ç»ƒ
python examples/llm-training/train_llama.py \
    --model_name_or_path "meta-llama/Llama-2-7b-hf" \
    --dataset_name "wikitext" \
    --output_dir ./outputs/llama-trained \
    --num_train_epochs 1

# æˆ–ä½¿ç”¨Makefile
make train-llama
```

### 3. ç§‘å­¦è®¡ç®—

#### 3.1 çŸ©é˜µè®¡ç®—æ€§èƒ½æµ‹è¯•
```python
# å¯åŠ¨Pythonç¯å¢ƒ
python

# æ‰§è¡ŒçŸ©é˜µè¿ç®—æµ‹è¯•
import torch
import time

# å¤§è§„æ¨¡çŸ©é˜µä¹˜æ³•
size = 4096
a = torch.randn(size, size, device='cuda')
b = torch.randn(size, size, device='cuda')

start_time = time.time()
c = torch.mm(a, b)
torch.cuda.synchronize()
end_time = time.time()

print(f"çŸ©é˜µä¹˜æ³•æ€§èƒ½: {(2 * size**3) / (end_time - start_time) / 1e12:.2f} TFLOPS")
```

#### 3.2 ç§‘å­¦è®¡ç®—åº”ç”¨
```bash
# æŸ¥çœ‹ç§‘å­¦è®¡ç®—ç¤ºä¾‹
python examples/llm-for-science/molecular_dynamics.py
python examples/llm-for-science/climate_simulation.py
```

## ğŸ–¥ï¸ æœåŠ¡è®¿é—®

é¡¹ç›®å¯åŠ¨åï¼Œå¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼è®¿é—®å„ç§æœåŠ¡ï¼š

| æœåŠ¡ | è®¿é—®åœ°å€ | æè¿° |
|------|----------|------|
| Jupyter Lab | http://localhost:8888 | äº¤äº’å¼å¼€å‘ç¯å¢ƒ |
| æ¨ç†API | http://localhost:8000 | FastAPIæ¨ç†æœåŠ¡ |
| Gradioç•Œé¢ | http://localhost:7860 | Webç•Œé¢æ¼”ç¤º |
| TensorBoard | http://localhost:6006 | è®­ç»ƒå¯è§†åŒ– |
| ç›‘æ§é¢æ¿ | http://localhost:9090 | æ€§èƒ½ç›‘æ§ |

### å¯åŠ¨Jupyter Lab
```bash
# Dockeræ–¹å¼
make jupyter

# æœ¬åœ°æ–¹å¼
make jupyter-local
```

### å¯åŠ¨æ¨ç†æœåŠ¡
```bash
# Dockeræ–¹å¼
make inference

# æœ¬åœ°æ–¹å¼
make inference-local
```

## ğŸ”§ å¸¸ç”¨å‘½ä»¤

### Dockerç›¸å…³
```bash
# æŸ¥çœ‹å¸®åŠ©
make help

# æ„å»ºé•œåƒ
make build

# å¯åŠ¨æœåŠ¡
make run
make run-all

# åœæ­¢æœåŠ¡
make stop

# é‡å¯æœåŠ¡
make restart

# è¿›å…¥å®¹å™¨
make shell

# æŸ¥çœ‹æ—¥å¿—
make logs
```

### å¼€å‘ç›¸å…³
```bash
# ç¯å¢ƒæ£€æŸ¥
make check

# å®‰è£…ä¾èµ–
make install

# ä»£ç æ ¼å¼åŒ–
make format

# è¿è¡Œæµ‹è¯•
make test

# æ€§èƒ½åŸºå‡†
make benchmark
```

### åº”ç”¨ç›¸å…³
```bash
# å¯åŠ¨Jupyter
make jupyter

# å¯åŠ¨æ¨ç†
make inference

# å¯åŠ¨è®­ç»ƒ
make train

# å¯åŠ¨ç›‘æ§
make monitor
```

## ğŸ“Š æ€§èƒ½è°ƒä¼˜

### 1. å†…å­˜ä¼˜åŒ–
```python
# å¯ç”¨æ··åˆç²¾åº¦
model = model.half()  # FP16

# æ¢¯åº¦æ£€æŸ¥ç‚¹
model.gradient_checkpointing_enable()

# æ¸…ç†æ˜¾å­˜
torch.cuda.empty_cache()
```

### 2. æ‰¹å¤„ç†ä¼˜åŒ–
```python
# åŠ¨æ€æ‰¹å¤„ç†
from torch.utils.data import DataLoader
dataloader = DataLoader(dataset, batch_size=4, shuffle=True)

# æ¢¯åº¦ç´¯ç§¯
accumulation_steps = 4
for i, batch in enumerate(dataloader):
    loss = model(batch)
    loss = loss / accumulation_steps
    loss.backward()
    
    if (i + 1) % accumulation_steps == 0:
        optimizer.step()
        optimizer.zero_grad()
```

### 3. åˆ†å¸ƒå¼è®­ç»ƒ
```bash
# å¤šDCUè®­ç»ƒ
torchrun --nproc_per_node=4 examples/llm-training/train_llama.py \
    --model_name_or_path "meta-llama/Llama-2-7b-hf" \
    --output_dir ./outputs/distributed-training
```

## ğŸ› æ•…éšœæ’æŸ¥

### å¸¸è§é—®é¢˜åŠè§£å†³æ–¹æ¡ˆ

#### 1. DCUè®¾å¤‡ä¸å¯ç”¨
```bash
# æ£€æŸ¥é©±åŠ¨
hy-smi

# æ£€æŸ¥æƒé™
ls -la /dev/dri/

# é‡æ–°åŠ è½½æ¨¡å—
sudo modprobe amdgpu
```

#### 2. å†…å­˜ä¸è¶³é”™è¯¯
```bash
# å‡å°‘æ‰¹æ¬¡å¤§å°
--per_device_train_batch_size 2

# å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹
--gradient_checkpointing True

# ä½¿ç”¨é‡åŒ–
--use_4bit True
```

#### 3. æ¨¡å‹ä¸‹è½½å¤±è´¥
```bash
# è®¾ç½®é•œåƒæº
export HF_ENDPOINT=https://hf-mirror.com

# æ‰‹åŠ¨ä¸‹è½½
huggingface-cli download model_name

# ä½¿ç”¨æœ¬åœ°æ¨¡å‹
--model_name_or_path /path/to/local/model
```

#### 4. Dockerç›¸å…³é—®é¢˜
```bash
# æ£€æŸ¥è®¾å¤‡æ˜ å°„
docker run --device /dev/dri:/dev/dri -it dcu-in-action:latest

# æŸ¥çœ‹å®¹å™¨æ—¥å¿—
make logs

# é‡å»ºé•œåƒ
make clean-all
make build
```

## ğŸ“š å­¦ä¹ èµ„æº

### æ–‡æ¡£èµ„æº
- [é¡¹ç›®æ–‡æ¡£](docs/): è¯¦ç»†çš„æŠ€æœ¯æ–‡æ¡£
- [APIæ–‡æ¡£](http://localhost:8000/docs): æ¨ç†æœåŠ¡API
- [å®˜æ–¹æ–‡æ¡£](https://developer.sourcefind.cn/): æµ·å…‰DCUå¼€å‘æ–‡æ¡£

### ç¤ºä¾‹ä»£ç 
- `examples/llm-inference/`: æ¨ç†ç¤ºä¾‹
- `examples/llm-training/`: è®­ç»ƒç¤ºä¾‹  
- `examples/llm-fine-tuning/`: å¾®è°ƒç¤ºä¾‹
- `examples/llm-for-science/`: ç§‘å­¦è®¡ç®—ç¤ºä¾‹

### ç¤¾åŒºæ”¯æŒ
- [GitHub Issues](https://github.com/hygon-technologies/dcu-in-action/issues)
- [å¼€å‘è€…ç¤¾åŒº](https://developer.sourcefind.cn/)
- [æŠ€æœ¯è®ºå›](https://bbs.sourcefind.cn/)

## ğŸš€ ä¸‹ä¸€æ­¥

å®Œæˆå¿«é€Ÿå¼€å§‹åï¼Œå»ºè®®æ‚¨ï¼š

1. **æ·±å…¥å­¦ä¹ **: é˜…è¯»[è¯¦ç»†æ–‡æ¡£](docs/)äº†è§£æ›´å¤šé«˜çº§åŠŸèƒ½
2. **å®è·µé¡¹ç›®**: ä½¿ç”¨è‡ªå·±çš„æ•°æ®å°è¯•è®­ç»ƒå’Œæ¨ç†
3. **æ€§èƒ½ä¼˜åŒ–**: æ ¹æ®åº”ç”¨éœ€æ±‚è°ƒä¼˜æ¨¡å‹å’Œç³»ç»Ÿå‚æ•°
4. **ç¤¾åŒºå‚ä¸**: åˆ†äº«ç»éªŒï¼Œå‚ä¸å¼€æºç¤¾åŒºå»ºè®¾

## â“ è·å–å¸®åŠ©

å¦‚æœé‡åˆ°é—®é¢˜ï¼š

1. é¦–å…ˆæŸ¥çœ‹[æ•…éšœæ’æŸ¥](#æ•…éšœæ’æŸ¥)éƒ¨åˆ†
2. æœç´¢[GitHub Issues](https://github.com/hygon-technologies/dcu-in-action/issues)
3. æŸ¥é˜…[å®˜æ–¹æ–‡æ¡£](https://developer.sourcefind.cn/)
4. åœ¨ç¤¾åŒºè®ºå›æé—®

---

**ç¥æ‚¨ä½¿ç”¨æ„‰å¿«ï¼ğŸ‰**

å¦‚æœæœ¬é¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ©ï¼Œè¯·ç»™æˆ‘ä»¬ä¸€ä¸ªâ­æ˜Ÿæ ‡æ”¯æŒï¼ 