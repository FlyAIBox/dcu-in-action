# ğŸš€ DCU-in-Action: æµ·å…‰DCUåŠ é€Ÿå¡å®æˆ˜æŒ‡å—

<div align="center">

![DCU Logo](https://img.shields.io/badge/æµ·å…‰DCU-åŠ é€Ÿè®¡ç®—-blue.svg)
![Python](https://img.shields.io/badge/Python-3.8+-green.svg)
![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)
![License](https://img.shields.io/badge/License-Apache%202.0-orange.svg)
![Status](https://img.shields.io/badge/Status-Production%20Ready-success.svg)

**åŸºäºæµ·å…‰DCUåŠ é€Ÿå¡çš„å¤§æ¨¡å‹è®­ç»ƒã€å¾®è°ƒã€æ¨ç†ä¸HPCç§‘å­¦è®¡ç®—å®Œæ•´å®æˆ˜æ–¹æ¡ˆ**

[ğŸš€ å¿«é€Ÿå¼€å§‹](#-å¿«é€Ÿå¼€å§‹) â€¢ [ğŸ“– æ•™ç¨‹æ–‡æ¡£](#-æ•™ç¨‹æ–‡æ¡£) â€¢ [ğŸ’¡ å®æˆ˜ç¤ºä¾‹](#-å®æˆ˜ç¤ºä¾‹) â€¢ [ğŸ› ï¸ å·¥å…·é“¾](#ï¸-æ ¸å¿ƒå·¥å…·é“¾) â€¢ [ğŸ—ï¸ æ¶æ„è®¾è®¡](#ï¸-ç³»ç»Ÿæ¶æ„)

</div>

---

## ğŸ“‹ é¡¹ç›®æ¦‚è¿°

DCUåŠ é€Ÿå¡æ˜¯ä¸€æ¬¾é¢å‘ç§‘å­¦è®¡ç®—ä¸äººå·¥æ™ºèƒ½é¢†åŸŸè®¾è®¡çš„å›½äº§åŠ é€Ÿå¡ï¼Œå…·å¤‡ä»¥ä¸‹æ ¸å¿ƒä¼˜åŠ¿ï¼š

- 1ã€**æ¶æ„ç‰¹æ€§ï¼š** å…¼å®¹å›½é™…ä¸»æµç”Ÿæ€ï¼ˆå¦‚ROCmï¼‰ï¼Œæ”¯æŒå¤§è§„æ¨¡å¹¶è¡Œè®¡ç®—ä¸é«˜ååæ•°æ®å¤„ç†ã€‚
- 2ã€**æŠ€æœ¯ç”Ÿæ€ï¼š** è¦†ç›–è™šæ‹ŸåŒ–ï¼ˆKVMã€K8sï¼‰ã€å¼‚æ„ç¼–ç¨‹ï¼ˆHIPã€OpenMP/ACCï¼‰ã€æ•°å­¦åº“ï¼ˆBLAS/FFTï¼‰ç­‰å…¨æ ˆå·¥å…·é“¾ã€‚
- 3ã€**åº”ç”¨åœºæ™¯ï¼š** é€‚é…å¤§æ¨¡å‹è®­ç»ƒï¼ˆå¦‚ChatGLM3ã€DeepSeekï¼‰ã€ç§‘å­¦è®¡ç®—ï¼ˆç§‘å­¦è®¡ç®—ã€AI4Scienceï¼‰ã€è¡Œä¸šå®è·µï¼ˆé‡‘èã€æ°”è±¡ã€ç”Ÿä¿¡ï¼‰ç­‰ã€‚

DCU-in-Action æ˜¯ä¸€ä¸ªé¢å‘ç”Ÿäº§ç¯å¢ƒçš„æµ·å…‰DCUåŠ é€Ÿå¡å®Œæ•´è§£å†³æ–¹æ¡ˆï¼Œæä¾›ä»ç¯å¢ƒæ­å»ºåˆ°æ¨¡å‹éƒ¨ç½²çš„å…¨æµç¨‹å·¥å…·é“¾ã€‚é¡¹ç›®ä¸“æ³¨äºå¤§æ¨¡å‹åº”ç”¨å’Œé«˜æ€§èƒ½è®¡ç®—ï¼Œä¸ºä¼ä¸šçº§AIåº”ç”¨æä¾›é«˜æ€§èƒ½ã€å¯æ‰©å±•çš„åŸºç¡€è®¾æ–½ã€‚

### ğŸ¯ æ ¸å¿ƒä»·å€¼

- **ğŸ”¥ å®æˆ˜å¯¼å‘**ï¼šåŸºäºçœŸå®ç”Ÿäº§ç¯å¢ƒçš„æœ€ä½³å®è·µ
- **ğŸ“š å®Œæ•´æ•™ç¨‹**ï¼šä»å…¥é—¨åˆ°ç²¾é€šçš„æ¸è¿›å¼å­¦ä¹ è·¯å¾„
- **ğŸ› ï¸ å·¥å…·é½å…¨**ï¼šå¼€ç®±å³ç”¨çš„å¼€å‘å’Œéƒ¨ç½²å·¥å…·é“¾
- **ğŸš€ æ€§èƒ½ä¼˜åŒ–**ï¼šä¸“ä¸ºDCUç¡¬ä»¶ä¼˜åŒ–çš„é«˜æ€§èƒ½å®ç°
- **ğŸŒŸ æŒç»­æ›´æ–°**ï¼šè·Ÿè¸ªæœ€æ–°æŠ€æœ¯æ ˆå’Œç¤¾åŒºå‘å±•

### âœ¨ æ ¸å¿ƒç‰¹æ€§

| åŠŸèƒ½æ¨¡å— | æè¿° | ç”Ÿäº§çŠ¶æ€ | 
|----------|------|----------|
| **ğŸ¤– å¤§æ¨¡å‹è®­ç»ƒ** | LLaMAã€ChatGLMã€Qwenç­‰é¢„è®­ç»ƒ | âœ… ç”Ÿäº§å°±ç»ª |
| **ğŸ¯ æ¨¡å‹å¾®è°ƒ** | LoRAã€QLoRAã€æŒ‡ä»¤å¾®è°ƒ | âœ… ç”Ÿäº§å°±ç»ª |
| **âš¡ æ¨ç†æœåŠ¡** | vLLMã€æ‰¹é‡æ¨ç†ã€æµå¼å¯¹è¯ | âœ… ç”Ÿäº§å°±ç»ª |
| **ğŸ”¬ HPCè®¡ç®—** | ç§‘å­¦è®¡ç®—ã€æ•°å€¼åˆ†æã€å¹¶è¡Œè®¡ç®— | âœ… ç”Ÿäº§å°±ç»ª |
| **ğŸ“Š æ€§èƒ½ç›‘æ§** | å®æ—¶ç›‘æ§ã€æ€§èƒ½åˆ†æã€èµ„æºç®¡ç† | âœ… ç”Ÿäº§å°±ç»ª |
| **ğŸ³ å®¹å™¨åŒ–éƒ¨ç½²** | Docker/K8sç”Ÿäº§ç¯å¢ƒéƒ¨ç½² | âœ… ç”Ÿäº§å°±ç»ª |

---

## ğŸ—ï¸ é¡¹ç›®æ¶æ„

```mermaid
graph TB
    subgraph "ç¡¬ä»¶å±‚"
        A[æµ·å…‰DCU BW1000/K100-AI/K100/Z100L/Z100]
    end
    
    subgraph "è¿è¡Œæ—¶å±‚"
        B[DTK 25.04+]
        C[ROCK 6.3.8+]
    end
    
    subgraph "æ¡†æ¶å±‚"
        D[PyTorch 2.4+]
        E[PaddlePaddle 2.5+]
        F[TensorFlow 2.13+]
    end
    
    subgraph "åº”ç”¨å±‚"
        G[å¤§æ¨¡å‹è®­ç»ƒ]
        H[æ¨¡å‹å¾®è°ƒ]
        I[æ¨ç†æœåŠ¡]
        J[HPCè®¡ç®—]
    end
    
    subgraph "å·¥å…·å±‚"
        K[æ€§èƒ½ç›‘æ§]
        L[å¼€å‘å·¥å…·]
        M[éƒ¨ç½²è„šæœ¬]
    end
    
    A --> B
    A --> C
    B --> D
    B --> E
    B --> F
    C --> D
    D --> G
    D --> H
    D --> I
    D --> J
    G --> K
    H --> L
    I --> M
```

---


### ğŸ”§ æŠ€æœ¯æ ˆ

| å±‚çº§ | æŠ€æœ¯ç»„ä»¶ | ç‰ˆæœ¬è¦æ±‚ | ç”¨é€” |
|------|----------|----------|------|
| **ç¡¬ä»¶å±‚** | æµ·å…‰DCU Z100/K100/K100-AI/BW1000 | - | åŠ é€Ÿè®¡ç®—ç¡¬ä»¶ |
| **é©±åŠ¨å±‚** | DCU Runtime | â‰¥ 5.0 | ç¡¬ä»¶é©±åŠ¨å’Œè¿è¡Œæ—¶ |
| **è®¡ç®—æ¡†æ¶** | PyTorch | â‰¥ 2.0 | æ·±åº¦å­¦ä¹ æ¡†æ¶ |
| **æ¨¡å‹åº“** | Transformers | â‰¥ 4.30 | é¢„è®­ç»ƒæ¨¡å‹åº“ |
| **æ¨ç†å¼•æ“** | vLLM | â‰¥ 0.2.0 | é«˜æ€§èƒ½æ¨ç†æœåŠ¡ |
| **å¾®è°ƒæ¡†æ¶** | LlamaFactory | â‰¥ 0.6.0 | æ¨¡å‹å¾®è°ƒå·¥å…· |
| **ç§‘å­¦è®¡ç®—** | NumPy/SciPy | Latest | æ•°å€¼è®¡ç®—åº“ |
| **å®¹å™¨åŒ–** | Docker/K8s | â‰¥ 20.10 | å®¹å™¨åŒ–éƒ¨ç½² |

---

## ğŸ“ é¡¹ç›®ç»“æ„

```
dcu-in-action/
â”œâ”€â”€ ğŸ“ common/                              # ğŸ”§ æ ¸å¿ƒå·¥å…·åº“
â”‚   â”œâ”€â”€ ğŸ“ dcu/                            # DCUç¡¬ä»¶ç®¡ç†
â”‚   â”‚   â”œâ”€â”€ device_manager.py              # è®¾å¤‡ç®¡ç†å’Œç›‘æ§
â”‚   â”‚   â”œâ”€â”€ memory_optimizer.py            # æ˜¾å­˜ä¼˜åŒ–ç­–ç•¥
â”‚   â”‚   â””â”€â”€ performance_profiler.py        # æ€§èƒ½åˆ†æå·¥å…·
â”‚   â”œâ”€â”€ ğŸ“ llm/                            # å¤§æ¨¡å‹å·¥å…·é“¾
â”‚   â”‚   â”œâ”€â”€ model_loader.py               # æ¨¡å‹åŠ è½½å’Œç®¡ç†
â”‚   â”‚   â”œâ”€â”€ tokenizer_utils.py            # åˆ†è¯å™¨å·¥å…·
â”‚   â”‚   â””â”€â”€ training_utils.py             # è®­ç»ƒè¾…åŠ©å·¥å…·
â”‚   â”œâ”€â”€ ğŸ“ hpc/                            # HPCè®¡ç®—å·¥å…·
â”‚   â”‚   â”œâ”€â”€ parallel_utils.py             # å¹¶è¡Œè®¡ç®—æ¡†æ¶
â”‚   â”‚   â””â”€â”€ numerical_solver.py           # æ•°å€¼æ±‚è§£å™¨
â”‚   â”œâ”€â”€ ğŸ“ utils/                          # é€šç”¨å·¥å…·
â”‚   â”‚   â”œâ”€â”€ config_manager.py             # é…ç½®ç®¡ç†ç³»ç»Ÿ
â”‚   â”‚   â”œâ”€â”€ logger.py                     # ç»Ÿä¸€æ—¥å¿—ç³»ç»Ÿ
â”‚   â”‚   â””â”€â”€ monitor.py                    # ç³»ç»Ÿç›‘æ§å·¥å…·
â”‚   â””â”€â”€ ğŸ“ setup/                          # ç¯å¢ƒé…ç½®
â”‚       â”œâ”€â”€ install_dependencies.sh       # è‡ªåŠ¨ä¾èµ–å®‰è£…
â”‚       â””â”€â”€ check_environment.sh          # ç¯å¢ƒæ£€æŸ¥è„šæœ¬
â”œâ”€â”€ ğŸ“ examples/                           # ğŸ¯ å®æˆ˜ç¤ºä¾‹
â”‚   â”œâ”€â”€ ğŸ“ training/                      # æ¨¡å‹è®­ç»ƒç¤ºä¾‹
â”‚   â”‚   â”œâ”€â”€ llama_pretraining/           # LLaMAé¢„è®­ç»ƒå®Œæ•´æµç¨‹
â”‚   â”‚   â”œâ”€â”€ chatglm_training/            # ChatGLMè®­ç»ƒå®æˆ˜
â”‚   â”‚   â””â”€â”€ distributed_training/        # åˆ†å¸ƒå¼è®­ç»ƒæ–¹æ¡ˆ
â”‚   â”œâ”€â”€ ğŸ“ finetuning/                    # æ¨¡å‹å¾®è°ƒç¤ºä¾‹
â”‚   â”‚   â”œâ”€â”€ llamafactory/                # LlamaFactoryå¾®è°ƒæ¡†æ¶
â”‚   â”‚   â”œâ”€â”€ lora_finetuning/             # LoRAé«˜æ•ˆå¾®è°ƒ
â”‚   â”‚   â”œâ”€â”€ qlora_finetuning/            # QLoRAé‡åŒ–å¾®è°ƒ
â”‚   â”‚   â””â”€â”€ instruction_tuning/          # æŒ‡ä»¤å¾®è°ƒå®æˆ˜
â”‚   â”œâ”€â”€ ğŸ“ inference/                     # æ¨ç†æœåŠ¡ç¤ºä¾‹
â”‚   â”‚   â”œâ”€â”€ vllm_serving/                # vLLMæ¨ç†æœåŠ¡éƒ¨ç½²
â”‚   â”‚   â”œâ”€â”€ batch_inference/             # æ‰¹é‡æ¨ç†ä¼˜åŒ–
â”‚   â”‚   â””â”€â”€ streaming_chat/              # æµå¼å¯¹è¯æœåŠ¡
â”‚   â”œâ”€â”€ ğŸ“ hpc/                          # HPCè®¡ç®—ç¤ºä¾‹
â”‚   â”‚   â”œâ”€â”€ matrix_computation/          # å¤§è§„æ¨¡çŸ©é˜µè®¡ç®—
â”‚   â”‚   â”œâ”€â”€ pde_solving/                 # åå¾®åˆ†æ–¹ç¨‹æ±‚è§£
â”‚   â”‚   â””â”€â”€ parallel_computing/          # å¹¶è¡Œè®¡ç®—ä¼˜åŒ–
â”‚   â””â”€â”€ ğŸ“ benchmarks/                    # æ€§èƒ½åŸºå‡†æµ‹è¯•
â”œâ”€â”€ ğŸ“ docs/                               # ğŸ“š å®Œæ•´æ–‡æ¡£
â”‚   â”œâ”€â”€ ğŸ“ tutorials/                     # åˆ†æ­¥æ•™ç¨‹
â”‚   â”‚   â”œâ”€â”€ 01-environment-setup.md       # ç¯å¢ƒæ­å»ºæŒ‡å—
â”‚   â”‚   â”œâ”€â”€ 02-model-training.md          # æ¨¡å‹è®­ç»ƒæ•™ç¨‹
â”‚   â”‚   â”œâ”€â”€ 03-model-finetuning.md        # æ¨¡å‹å¾®è°ƒæŒ‡å—
â”‚   â”‚   â”œâ”€â”€ 04-model-inference.md         # æ¨¡å‹æ¨ç†éƒ¨ç½²
â”‚   â”‚   â””â”€â”€ 05-hpc-computing.md           # HPCè®¡ç®—å®æˆ˜
â”‚   â”œâ”€â”€ ğŸ“ api/                           # APIå‚è€ƒæ–‡æ¡£
â”‚   â””â”€â”€ ğŸ“ architecture/                  # æ¶æ„è®¾è®¡æ–‡æ¡£
â”œâ”€â”€ ğŸ“ configs/                           # âš™ï¸ é…ç½®æ–‡ä»¶
â”‚   â”œâ”€â”€ ğŸ“ models/                       # æ¨¡å‹é…ç½®æ¨¡æ¿
â”‚   â”œâ”€â”€ ğŸ“ training/                     # è®­ç»ƒé…ç½®æ¨¡æ¿
â”‚   â””â”€â”€ ğŸ“ inference/                    # æ¨ç†é…ç½®æ¨¡æ¿
â”œâ”€â”€ ğŸ“ scripts/                           # ğŸ”§ è‡ªåŠ¨åŒ–è„šæœ¬
â”‚   â”œâ”€â”€ ğŸ“ setup/                        # ç¯å¢ƒé…ç½®è„šæœ¬
â”‚   â”œâ”€â”€ ğŸ“ deployment/                   # éƒ¨ç½²è‡ªåŠ¨åŒ–è„šæœ¬
â”‚   â””â”€â”€ ğŸ“ monitoring/                   # ç›‘æ§è„šæœ¬
â”œâ”€â”€ ğŸ“ tests/                            # ğŸ§ª æµ‹è¯•ç”¨ä¾‹
â””â”€â”€ ğŸ“„ README.md                        # é¡¹ç›®è¯´æ˜æ–‡æ¡£
```

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ğŸ“‹ ç¯å¢ƒè¦æ±‚

| ç»„ä»¶ | æœ€ä½è¦æ±‚ | æ¨èé…ç½® |
|------|----------|----------|
| **æ“ä½œç³»ç»Ÿ** | Ubuntu 20.04+ | Ubuntu 22.04 LTS |
| **Python** | 3.8+ | 3.10+ |
| **DCUé©±åŠ¨** | 5.0+ | æœ€æ–°ç‰ˆæœ¬ |
| **å†…å­˜** | 32GB | 64GB+ |
| **å­˜å‚¨** | 500GB | 2TB+ SSD |

### âš¡ ä¸€é”®å®‰è£…

```bash
# 1. å…‹éš†é¡¹ç›®
git clone https://github.com/your-org/dcu-in-action.git
cd dcu-in-action

# 2. è‡ªåŠ¨ç¯å¢ƒæ£€æŸ¥å’Œå®‰è£…
make install

# 3. éªŒè¯å®‰è£…
make test
```

### ğŸ”§ æ‰‹åŠ¨å®‰è£…

```bash
# 1. æ£€æŸ¥DCUç¯å¢ƒ
./common/setup/check_environment.sh

# 2. å®‰è£…Pythonä¾èµ–
pip install -r requirements.txt

# 3. å®‰è£…DCUç›¸å…³ä¾èµ–
./common/setup/install_dependencies.sh

# 4. é…ç½®ç¯å¢ƒå˜é‡
export DCU_VISIBLE_DEVICES=0
export PYTHONPATH=$PWD:$PYTHONPATH
```

### ğŸ¯ å¿«é€ŸéªŒè¯

```bash
# éªŒè¯DCUè®¾å¤‡
python -c "from common.dcu import device_manager; print(device_manager.get_device_info())"

# è¿è¡ŒåŸºç¡€ç¤ºä¾‹
cd examples/basic
python hello_dcu.py

# è¿è¡Œæ€§èƒ½åŸºå‡†
cd examples/benchmarks
python dcu_benchmark.py
```

---

## ğŸ’¡ å®æˆ˜ç¤ºä¾‹

### ğŸ¤– å¤§æ¨¡å‹è®­ç»ƒ

#### LLaMAé¢„è®­ç»ƒ
```bash
cd examples/training/llama_pretraining
python train_llama.py --config configs/llama_7b.yaml
```

#### åˆ†å¸ƒå¼è®­ç»ƒ
```bash
cd examples/training/distributed_training
torchrun --nproc_per_node=4 train_distributed.py
```

### ğŸ¯ æ¨¡å‹å¾®è°ƒ

#### LoRAå¾®è°ƒ
```bash
cd examples/finetuning/lora_finetuning
python lora_finetune.py --model_name llama2-7b --dataset alpaca
```

#### LlamaFactoryå¾®è°ƒ
```bash
cd examples/finetuning/llamafactory
llamafactory-cli train --config_path configs/lora_config.yaml
```

### âš¡ æ¨ç†æœåŠ¡

#### vLLMæ¨ç†æœåŠ¡
```bash
cd examples/inference/vllm_serving
python -m vllm.entrypoints.api_server \
    --model /path/to/model \
    --tensor-parallel-size 4
```

#### æµå¼å¯¹è¯æœåŠ¡
```bash
cd examples/inference/streaming_chat
python chat_server.py --model_path /path/to/model
```

### ğŸ”¬ HPCç§‘å­¦è®¡ç®—

#### å¤§è§„æ¨¡çŸ©é˜µè®¡ç®—
```bash
cd examples/hpc/matrix_computation
python large_matrix_ops.py --size 10000 --precision float32
```

#### åå¾®åˆ†æ–¹ç¨‹æ±‚è§£
```bash
cd examples/hpc/pde_solving
python heat_equation_solver.py --grid_size 1024
```

---

## ğŸ› ï¸ æ ¸å¿ƒå·¥å…·é“¾

### ğŸ“Š æ€§èƒ½ç›‘æ§

```python
from common.utils.monitor import DCUMonitor

# å®æ—¶ç›‘æ§DCUä½¿ç”¨æƒ…å†µ
monitor = DCUMonitor()
monitor.start_monitoring()

# è·å–æ€§èƒ½æŠ¥å‘Š
report = monitor.get_performance_report()
print(report)
```

### ğŸ”§ è®¾å¤‡ç®¡ç†

```python
from common.dcu.device_manager import DCUDeviceManager

# è‡ªåŠ¨è®¾å¤‡ç®¡ç†
device_manager = DCUDeviceManager()
device_manager.optimize_memory()
device_manager.set_performance_mode('high')
```

### ğŸ“ˆ æ€§èƒ½åˆ†æ

```python
from common.dcu.performance_profiler import DCUProfiler

# æ€§èƒ½åˆ†æ
with DCUProfiler() as profiler:
    # ä½ çš„ä»£ç 
    model.forward(inputs)

# ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š
profiler.generate_report('performance_report.html')
```

---

## ğŸ“– æ•™ç¨‹æ–‡æ¡£

### ğŸ“ å…¥é—¨æ•™ç¨‹
- [ç¯å¢ƒæ­å»ºæŒ‡å—](docs/tutorials/01-environment-setup.md) - ä»é›¶å¼€å§‹æ­å»ºDCUå¼€å‘ç¯å¢ƒ
- [ç¬¬ä¸€ä¸ªDCUç¨‹åº](docs/tutorials/02-first-dcu-program.md) - Hello DCUç¤ºä¾‹

### ğŸš€ è¿›é˜¶æ•™ç¨‹
- [å¤§æ¨¡å‹è®­ç»ƒå®æˆ˜](docs/tutorials/02-model-training.md) - å®Œæ•´çš„æ¨¡å‹è®­ç»ƒæµç¨‹
- [é«˜æ•ˆæ¨¡å‹å¾®è°ƒ](docs/tutorials/03-model-finetuning.md) - LoRA/QLoRAå¾®è°ƒæŠ€æœ¯
- [æ¨ç†æœåŠ¡éƒ¨ç½²](docs/tutorials/04-model-inference.md) - ç”Ÿäº§ç¯å¢ƒæ¨ç†æœåŠ¡

### ğŸ”¬ ä¸“ä¸šæ•™ç¨‹
- [HPCç§‘å­¦è®¡ç®—](docs/tutorials/05-hpc-computing.md) - é«˜æ€§èƒ½ç§‘å­¦è®¡ç®—åº”ç”¨
- [åˆ†å¸ƒå¼è®­ç»ƒ](docs/tutorials/06-distributed-training.md) - å¤§è§„æ¨¡åˆ†å¸ƒå¼è®­ç»ƒ
- [æ€§èƒ½ä¼˜åŒ–æŒ‡å—](docs/tutorials/07-performance-optimization.md) - æ·±åº¦æ€§èƒ½ä¼˜åŒ–æŠ€å·§

---

## ğŸ³ å®¹å™¨åŒ–éƒ¨ç½²

### Dockeréƒ¨ç½²

```bash
# æ„å»ºé•œåƒ
docker build -t dcu-in-action:latest .

# è¿è¡Œå®¹å™¨
docker run --device=/dev/kfd --device=/dev/dri \
    -v $(pwd):/workspace \
    dcu-in-action:latest
```

### Kuberneteséƒ¨ç½²

```bash
# éƒ¨ç½²åˆ°K8sé›†ç¾¤
kubectl apply -f k8s/

# æŸ¥çœ‹æœåŠ¡çŠ¶æ€
kubectl get pods -l app=dcu-in-action
```

### Docker Compose

```bash
# å¯åŠ¨å®Œæ•´æœåŠ¡æ ˆ
docker-compose up -d

# æŸ¥çœ‹æœåŠ¡çŠ¶æ€
docker-compose ps
```

---

## ğŸ¤ è´¡çŒ®æŒ‡å—

æˆ‘ä»¬æ¬¢è¿æ‰€æœ‰å½¢å¼çš„è´¡çŒ®ï¼è¯·é˜…è¯»æˆ‘ä»¬çš„[è´¡çŒ®æŒ‡å—](CONTRIBUTING.md)äº†è§£è¯¦æƒ…ã€‚

### å¦‚ä½•è´¡çŒ®
1. **Fork** æœ¬é¡¹ç›®
2. **åˆ›å»º** ç‰¹æ€§åˆ†æ”¯ (`git checkout -b feature/AmazingFeature`)
3. **æäº¤** æ›´æ”¹ (`git commit -m 'Add some AmazingFeature'`)
4. **æ¨é€** åˆ°åˆ†æ”¯ (`git push origin feature/AmazingFeature`)
5. **åˆ›å»º** Pull Request

### è´¡çŒ®ç±»å‹
- ğŸ› Bugä¿®å¤
- âœ¨ æ–°åŠŸèƒ½å¼€å‘
- ğŸ“ æ–‡æ¡£æ”¹è¿›
- ğŸ¨ ä»£ç ä¼˜åŒ–
- ğŸ§ª æµ‹è¯•ç”¨ä¾‹
- ğŸŒ å¤šè¯­è¨€æ”¯æŒ

---
## âš ï¸ å…è´£å£°æ˜

 æœ¬é¡¹ç›®åŸºäºæµ·å…‰DCUå¼€å‘ç¤¾åŒºå…¬å¼€èµ„æ–™å’Œæœ€ä½³å®è·µæ•´ç†ï¼Œä»…ä¾›å­¦ä¹ ç ”ç©¶ä½¿ç”¨ã€‚
 
 - âœ… æ‰€æœ‰ä»£ç å’Œæ–‡æ¡£å‡åŸºäºå…¬å¼€æŠ€æœ¯èµ„æ–™
 - âš ï¸ è¯·ä»¥å®˜æ–¹æœ€æ–°æ–‡æ¡£ä¸ºå‡†
 - ğŸ“‹ ä½¿ç”¨æ—¶è¯·éµå®ˆç›¸å…³æ³•å¾‹æ³•è§„
 - ğŸ›¡ï¸ é¡¹ç›®ç»´æŠ¤è€…ä¸æ‰¿æ‹…ä½¿ç”¨é£é™©

---

## ğŸ™ è‡´è°¢

æ„Ÿè°¢ä»¥ä¸‹é¡¹ç›®å’Œç»„ç»‡çš„æ”¯æŒï¼š

<table>
<tr>
<td align="center">
<img src="https://upload.wikimedia.org/wikipedia/commons/5/50/Hygon_Information_Technology.png" width="60">
<br>æµ·å…‰ä¿¡æ¯
</td>
<td align="center">
<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/7/7b/ROCm_logo.png/500px-ROCm_logo.png" width="60">
<br>ROCmç¤¾åŒº
</td>
<td align="center">
<img src="https://pytorch.org/assets/images/logo-dark.svg" width="60">
<br>PyTorch
</td>
<td align="center">
<img src="https://raw.githubusercontent.com/hiyouga/LLaMA-Factory/main/assets/logo.png" width="60">
<br>LLaMA Factory
</td>
</tr>
</table>


ç‰¹åˆ«æ„Ÿè°¢æ‰€æœ‰è´¡çŒ®è€…å’Œç¤¾åŒºæˆå‘˜çš„æ”¯æŒï¼

---

<div align="center">

**â­ å¦‚æœè¿™ä¸ªé¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ©ï¼Œè¯·ç»™ä¸ªStaræ”¯æŒï¼â­**

<a href="https://star-history.com/#FlyAIBox/dcu-in-action&Date">
  <picture>
    <source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=FlyAIBox/dcu-in-action&type=Date&theme=dark" />
    <source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=FlyAIBox/dcu-in-action&type=Date" />
    <img alt="Star History Chart" src="https://api.star-history.com/svg?repos=FlyAIBox/dcu-in-action&type=Date" />
  </picture>
</a>

**ğŸ”— æ›´å¤šDCUèµ„æºï¼š[æµ·å…‰DCUå¼€å‘è€…ç¤¾åŒº](https://developer.sourcefind.cn/)**

</div>