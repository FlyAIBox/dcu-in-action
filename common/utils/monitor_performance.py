#!/usr/bin/env python3
"""
æµ·å…‰DCUæ€§èƒ½ç›‘æ§å·¥å…·
å®æ—¶ç›‘æ§DCUè®¾å¤‡çŠ¶æ€ã€å†…å­˜ä½¿ç”¨ã€æ¸©åº¦ç­‰ä¿¡æ¯
"""

import time
import subprocess
import json
import argparse
import signal
import sys
from datetime import datetime
from typing import Dict, List, Optional
import threading

try:
    import torch
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False

try:
    import psutil
    PSUTIL_AVAILABLE = True
except ImportError:
    PSUTIL_AVAILABLE = False

class DCUMonitor:
    def __init__(self, interval=2, log_file=None, json_output=False):
        """
        DCUæ€§èƒ½ç›‘æ§å™¨
        
        Args:
            interval: ç›‘æ§é—´éš”(ç§’)
            log_file: æ—¥å¿—æ–‡ä»¶è·¯å¾„
            json_output: æ˜¯å¦è¾“å‡ºJSONæ ¼å¼
        """
        self.interval = interval
        self.log_file = log_file
        self.json_output = json_output
        self.running = True
        self.start_time = time.time()
        
        # è®¾ç½®ä¿¡å·å¤„ç†
        signal.signal(signal.SIGINT, self._signal_handler)
        signal.signal(signal.SIGTERM, self._signal_handler)
        
        # åˆå§‹åŒ–æ—¥å¿—æ–‡ä»¶
        if self.log_file:
            with open(self.log_file, 'w') as f:
                f.write("timestamp,device_id,gpu_util,memory_used,memory_total,temperature,power\n")
    
    def _signal_handler(self, signum, frame):
        """ä¿¡å·å¤„ç†å‡½æ•°"""
        print("\næ­£åœ¨åœæ­¢ç›‘æ§...")
        self.running = False
    
    def get_dcu_info_via_smi(self) -> List[Dict]:
        """é€šè¿‡hy-smiå‘½ä»¤è·å–DCUä¿¡æ¯"""
        try:
            # å°è¯•è¿è¡Œhy-smi
            result = subprocess.run(['hy-smi', '--json'], 
                                  capture_output=True, text=True, timeout=10)
            
            if result.returncode == 0:
                return json.loads(result.stdout)
            else:
                return []
                
        except (subprocess.TimeoutExpired, subprocess.CalledProcessError, 
                FileNotFoundError, json.JSONDecodeError):
            return []
    
    def get_dcu_info_via_torch(self) -> List[Dict]:
        """é€šè¿‡PyTorchè·å–DCUä¿¡æ¯"""
        if not TORCH_AVAILABLE or not torch.cuda.is_available():
            return []
        
        devices = []
        for i in range(torch.cuda.device_count()):
            try:
                # è·å–è®¾å¤‡å±æ€§
                props = torch.cuda.get_device_properties(i)
                
                # è·å–å†…å­˜ä¿¡æ¯
                memory_allocated = torch.cuda.memory_allocated(i)
                memory_reserved = torch.cuda.memory_reserved(i)
                memory_total = props.total_memory
                
                device_info = {
                    'device_id': i,
                    'name': props.name,
                    'memory_allocated': memory_allocated,
                    'memory_reserved': memory_reserved,
                    'memory_total': memory_total,
                    'memory_util': (memory_allocated / memory_total) * 100,
                    'compute_capability': f"{props.major}.{props.minor}",
                    'multiprocessor_count': props.multi_processor_count
                }
                
                devices.append(device_info)
                
            except Exception as e:
                print(f"è·å–è®¾å¤‡ {i} ä¿¡æ¯å¤±è´¥: {e}")
                
        return devices
    
    def get_system_info(self) -> Dict:
        """è·å–ç³»ç»Ÿä¿¡æ¯"""
        system_info = {
            'timestamp': datetime.now().isoformat(),
            'cpu_percent': 0,
            'memory_percent': 0,
            'memory_available': 0,
            'load_average': [0, 0, 0]
        }
        
        if PSUTIL_AVAILABLE:
            try:
                # CPUä½¿ç”¨ç‡
                system_info['cpu_percent'] = psutil.cpu_percent(interval=None)
                
                # å†…å­˜ä¿¡æ¯
                memory = psutil.virtual_memory()
                system_info['memory_percent'] = memory.percent
                system_info['memory_available'] = memory.available
                
                # è´Ÿè½½å¹³å‡å€¼
                system_info['load_average'] = list(psutil.getloadavg())
                
            except Exception as e:
                print(f"è·å–ç³»ç»Ÿä¿¡æ¯å¤±è´¥: {e}")
        
        return system_info
    
    def format_bytes(self, bytes_val):
        """æ ¼å¼åŒ–å­—èŠ‚æ•°"""
        for unit in ['B', 'KB', 'MB', 'GB', 'TB']:
            if bytes_val < 1024.0:
                return f"{bytes_val:.1f} {unit}"
            bytes_val /= 1024.0
        return f"{bytes_val:.1f} PB"
    
    def display_header(self):
        """æ˜¾ç¤ºè¡¨å¤´"""
        if self.json_output:
            return
            
        print("\n" + "="*80)
        print(f"{'DCUç›‘æ§å™¨':<20} {'è¿è¡Œæ—¶é—´':<15} {'åˆ·æ–°é—´éš”':<10} {'æ—¶é—´':<20}")
        print("="*80)
        
        print(f"{'è®¾å¤‡':<6} {'åç§°':<15} {'GPUä½¿ç”¨':<10} {'æ˜¾å­˜':<20} {'æ¸©åº¦':<8} {'åŠŸè€—':<8}")
        print("-"*80)
    
    def display_devices(self, devices):
        """æ˜¾ç¤ºè®¾å¤‡ä¿¡æ¯"""
        current_time = datetime.now().strftime("%H:%M:%S")
        runtime = time.time() - self.start_time
        
        if self.json_output:
            output = {
                'timestamp': current_time,
                'runtime': runtime,
                'devices': devices
            }
            print(json.dumps(output, indent=2))
            return
        
        # æ¸…å±å¹¶æ˜¾ç¤ºè¡¨å¤´
        print("\033[2J\033[H", end="")  # æ¸…å±å¹¶ç§»åŠ¨å…‰æ ‡åˆ°å·¦ä¸Šè§’
        
        print(f"ğŸ–¥ï¸  DCUç›‘æ§å™¨ v1.0    â±ï¸  è¿è¡Œæ—¶é—´: {runtime:.0f}s    ğŸ”„ é—´éš”: {self.interval}s    ğŸ“… {current_time}")
        print("="*80)
        
        if not devices:
            print("âŒ æœªæ£€æµ‹åˆ°DCUè®¾å¤‡æˆ–è·å–ä¿¡æ¯å¤±è´¥")
            print("   è¯·æ£€æŸ¥:")
            print("   1. DCUé©±åŠ¨æ˜¯å¦æ­£ç¡®å®‰è£…")
            print("   2. hy-smiå‘½ä»¤æ˜¯å¦å¯ç”¨")
            print("   3. PyTorchæ˜¯å¦æ”¯æŒDCU")
            return
        
        print(f"{'è®¾å¤‡':<6} {'åç§°':<15} {'GPUä½¿ç”¨':<10} {'æ˜¾å­˜ä½¿ç”¨':<25} {'æ¸©åº¦':<8} {'åŠŸè€—':<8}")
        print("-"*80)
        
        for device in devices:
            device_id = device.get('device_id', 'N/A')
            name = device.get('name', 'Unknown')[:14]
            
            # GPUä½¿ç”¨ç‡
            gpu_util = device.get('gpu_utilization', device.get('memory_util', 0))
            gpu_util_str = f"{gpu_util:.1f}%" if gpu_util else "N/A"
            
            # å†…å­˜ä¿¡æ¯
            memory_used = device.get('memory_allocated', device.get('memory_used', 0))
            memory_total = device.get('memory_total', 1)
            memory_percent = (memory_used / memory_total * 100) if memory_total > 0 else 0
            
            memory_str = f"{self.format_bytes(memory_used)}/{self.format_bytes(memory_total)} ({memory_percent:.1f}%)"
            
            # æ¸©åº¦
            temperature = device.get('temperature', 0)
            temp_str = f"{temperature}Â°C" if temperature else "N/A"
            
            # åŠŸè€—
            power = device.get('power', 0)
            power_str = f"{power}W" if power else "N/A"
            
            print(f"DCU{device_id:<3} {name:<15} {gpu_util_str:<10} {memory_str:<25} {temp_str:<8} {power_str:<8}")
        
        # æ˜¾ç¤ºç³»ç»Ÿä¿¡æ¯
        system_info = self.get_system_info()
        print("\n" + "-"*80)
        print(f"ğŸ’» ç³»ç»ŸçŠ¶æ€:")
        print(f"   CPUä½¿ç”¨ç‡: {system_info['cpu_percent']:.1f}%")
        print(f"   å†…å­˜ä½¿ç”¨ç‡: {system_info['memory_percent']:.1f}%")
        print(f"   å¯ç”¨å†…å­˜: {self.format_bytes(system_info['memory_available'])}")
        print(f"   è´Ÿè½½å¹³å‡: {system_info['load_average'][0]:.2f}, {system_info['load_average'][1]:.2f}, {system_info['load_average'][2]:.2f}")
    
    def log_to_file(self, devices):
        """è®°å½•æ•°æ®åˆ°æ–‡ä»¶"""
        if not self.log_file:
            return
            
        timestamp = datetime.now().isoformat()
        
        try:
            with open(self.log_file, 'a') as f:
                for device in devices:
                    line = f"{timestamp},{device.get('device_id', 'N/A')}," \
                           f"{device.get('gpu_utilization', 0)}," \
                           f"{device.get('memory_used', 0)}," \
                           f"{device.get('memory_total', 0)}," \
                           f"{device.get('temperature', 0)}," \
                           f"{device.get('power', 0)}\n"
                    f.write(line)
        except Exception as e:
            print(f"å†™å…¥æ—¥å¿—æ–‡ä»¶å¤±è´¥: {e}")
    
    def run(self):
        """è¿è¡Œç›‘æ§å¾ªç¯"""
        print("ğŸš€ å¯åŠ¨DCUç›‘æ§å™¨...")
        print("æŒ‰ Ctrl+C åœæ­¢ç›‘æ§")
        
        if not self.json_output:
            self.display_header()
        
        while self.running:
            try:
                # å°è¯•é€šè¿‡hy-smiè·å–ä¿¡æ¯
                devices = self.get_dcu_info_via_smi()
                
                # å¦‚æœhy-smiå¤±è´¥ï¼Œå°è¯•é€šè¿‡PyTorchè·å–
                if not devices:
                    devices = self.get_dcu_info_via_torch()
                
                # æ˜¾ç¤ºä¿¡æ¯
                self.display_devices(devices)
                
                # è®°å½•åˆ°æ–‡ä»¶
                self.log_to_file(devices)
                
                # ç­‰å¾…ä¸‹ä¸€æ¬¡åˆ·æ–°
                time.sleep(self.interval)
                
            except KeyboardInterrupt:
                break
            except Exception as e:
                print(f"ç›‘æ§è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
                time.sleep(self.interval)
        
        print("\nç›‘æ§å·²åœæ­¢")

class DCUBenchmark:
    """DCUæ€§èƒ½åŸºå‡†æµ‹è¯•"""
    
    def __init__(self):
        self.device_count = 0
        if TORCH_AVAILABLE and torch.cuda.is_available():
            self.device_count = torch.cuda.device_count()
    
    def memory_bandwidth_test(self, device_id=0, size_mb=1024):
        """å†…å­˜å¸¦å®½æµ‹è¯•"""
        if not TORCH_AVAILABLE or not torch.cuda.is_available():
            print("PyTorchæˆ–DCUä¸å¯ç”¨")
            return
        
        print(f"ğŸ“Š DCU {device_id} å†…å­˜å¸¦å®½æµ‹è¯• (æ•°æ®å¤§å°: {size_mb} MB)")
        
        device = torch.device(f'cuda:{device_id}')
        size = size_mb * 1024 * 1024 // 4  # è½¬æ¢ä¸ºfloat32æ•°é‡
        
        # ä¸»æœºåˆ°è®¾å¤‡
        host_data = torch.randn(size)
        
        torch.cuda.synchronize()
        start_time = time.time()
        device_data = host_data.to(device)
        torch.cuda.synchronize()
        h2d_time = time.time() - start_time
        
        h2d_bandwidth = (size_mb / h2d_time) * 1000  # MB/s
        
        # è®¾å¤‡åˆ°ä¸»æœº
        torch.cuda.synchronize()
        start_time = time.time()
        host_result = device_data.cpu()
        torch.cuda.synchronize()
        d2h_time = time.time() - start_time
        
        d2h_bandwidth = (size_mb / d2h_time) * 1000  # MB/s
        
        print(f"   ä¸»æœºåˆ°è®¾å¤‡: {h2d_bandwidth:.1f} MB/s")
        print(f"   è®¾å¤‡åˆ°ä¸»æœº: {d2h_bandwidth:.1f} MB/s")
        
        return h2d_bandwidth, d2h_bandwidth
    
    def compute_performance_test(self, device_id=0, matrix_size=2048):
        """è®¡ç®—æ€§èƒ½æµ‹è¯•"""
        if not TORCH_AVAILABLE or not torch.cuda.is_available():
            print("PyTorchæˆ–DCUä¸å¯ç”¨")
            return
        
        print(f"ğŸ§® DCU {device_id} è®¡ç®—æ€§èƒ½æµ‹è¯• (çŸ©é˜µå¤§å°: {matrix_size}x{matrix_size})")
        
        device = torch.device(f'cuda:{device_id}')
        
        # ç”Ÿæˆæµ‹è¯•æ•°æ®
        a = torch.randn(matrix_size, matrix_size, device=device, dtype=torch.float32)
        b = torch.randn(matrix_size, matrix_size, device=device, dtype=torch.float32)
        
        # é¢„çƒ­
        for _ in range(10):
            _ = torch.mm(a, b)
        torch.cuda.synchronize()
        
        # æ€§èƒ½æµ‹è¯•
        iterations = 100
        torch.cuda.synchronize()
        start_time = time.time()
        
        for _ in range(iterations):
            c = torch.mm(a, b)
        
        torch.cuda.synchronize()
        end_time = time.time()
        
        total_time = end_time - start_time
        avg_time = total_time / iterations
        
        # è®¡ç®—FLOPS
        flops = 2 * matrix_size**3  # çŸ©é˜µä¹˜æ³•çš„æµ®ç‚¹è¿ç®—æ•°
        gflops = flops / (avg_time * 1e9)
        
        print(f"   å¹³å‡æ—¶é—´: {avg_time*1000:.2f} ms")
        print(f"   æ€§èƒ½: {gflops:.1f} GFLOPS")
        
        return gflops
    
    def run_full_benchmark(self):
        """è¿è¡Œå®Œæ•´çš„åŸºå‡†æµ‹è¯•"""
        if not TORCH_AVAILABLE or not torch.cuda.is_available():
            print("âŒ PyTorchæˆ–DCUä¸å¯ç”¨ï¼Œæ— æ³•è¿è¡ŒåŸºå‡†æµ‹è¯•")
            return
        
        print("ğŸš€ å¼€å§‹DCUå®Œæ•´åŸºå‡†æµ‹è¯•...")
        print(f"æ£€æµ‹åˆ° {self.device_count} ä¸ªDCUè®¾å¤‡\n")
        
        for device_id in range(self.device_count):
            print(f"{'='*60}")
            print(f"è®¾å¤‡ {device_id}: {torch.cuda.get_device_name(device_id)}")
            print(f"{'='*60}")
            
            # å†…å­˜å¸¦å®½æµ‹è¯•
            self.memory_bandwidth_test(device_id)
            print()
            
            # è®¡ç®—æ€§èƒ½æµ‹è¯• - ä¸åŒçŸ©é˜µå¤§å°
            for size in [1024, 2048, 4096]:
                try:
                    self.compute_performance_test(device_id, size)
                except RuntimeError as e:
                    if "out of memory" in str(e):
                        print(f"   çŸ©é˜µå¤§å° {size}: å†…å­˜ä¸è¶³ï¼Œè·³è¿‡")
                        break
                    else:
                        raise e
            print()

def main():
    parser = argparse.ArgumentParser(description="æµ·å…‰DCUæ€§èƒ½ç›‘æ§å·¥å…·")
    
    subparsers = parser.add_subparsers(dest='command', help='å¯ç”¨å‘½ä»¤')
    
    # ç›‘æ§å‘½ä»¤
    monitor_parser = subparsers.add_parser('monitor', help='å®æ—¶ç›‘æ§DCUçŠ¶æ€')
    monitor_parser.add_argument('-i', '--interval', type=float, default=2.0, 
                              help='ç›‘æ§é—´éš”(ç§’), é»˜è®¤2ç§’')
    monitor_parser.add_argument('-l', '--log', type=str, 
                              help='æ—¥å¿—æ–‡ä»¶è·¯å¾„')
    monitor_parser.add_argument('-j', '--json', action='store_true',
                              help='è¾“å‡ºJSONæ ¼å¼')
    
    # åŸºå‡†æµ‹è¯•å‘½ä»¤
    benchmark_parser = subparsers.add_parser('benchmark', help='è¿è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•')
    benchmark_parser.add_argument('-d', '--device', type=int, default=0,
                                help='æµ‹è¯•çš„è®¾å¤‡ID')
    benchmark_parser.add_argument('-s', '--size', type=int, default=2048,
                                help='çŸ©é˜µå¤§å°')
    benchmark_parser.add_argument('--memory-test', action='store_true',
                                help='ä»…è¿è¡Œå†…å­˜å¸¦å®½æµ‹è¯•')
    benchmark_parser.add_argument('--compute-test', action='store_true',
                                help='ä»…è¿è¡Œè®¡ç®—æ€§èƒ½æµ‹è¯•')
    
    # ä¿¡æ¯å‘½ä»¤
    info_parser = subparsers.add_parser('info', help='æ˜¾ç¤ºDCUè®¾å¤‡ä¿¡æ¯')
    
    args = parser.parse_args()
    
    if args.command == 'monitor':
        monitor = DCUMonitor(
            interval=args.interval,
            log_file=args.log,
            json_output=args.json
        )
        monitor.run()
        
    elif args.command == 'benchmark':
        benchmark = DCUBenchmark()
        
        if args.memory_test:
            benchmark.memory_bandwidth_test(args.device)
        elif args.compute_test:
            benchmark.compute_performance_test(args.device, args.size)
        else:
            benchmark.run_full_benchmark()
            
    elif args.command == 'info':
        monitor = DCUMonitor()
        devices = monitor.get_dcu_info_via_torch()
        
        if devices:
            print("ğŸ–¥ï¸  DCUè®¾å¤‡ä¿¡æ¯:")
            print("="*50)
            for device in devices:
                print(f"è®¾å¤‡ {device['device_id']}: {device['name']}")
                print(f"  æ€»å†…å­˜: {monitor.format_bytes(device['memory_total'])}")
                print(f"  è®¡ç®—èƒ½åŠ›: {device['compute_capability']}")
                print(f"  å¤šå¤„ç†å™¨æ•°é‡: {device['multiprocessor_count']}")
                print()
        else:
            print("âŒ æœªæ£€æµ‹åˆ°DCUè®¾å¤‡")
    
    else:
        parser.print_help()

if __name__ == "__main__":
    main() 