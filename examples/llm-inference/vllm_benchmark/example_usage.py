#!/usr/bin/env python3
"""
vLLMåŸºå‡†æµ‹è¯•å¯è§†åŒ–å·¥å…·ä½¿ç”¨ç¤ºä¾‹

æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨BenchmarkVisualizerç±»è¿›è¡Œæ•°æ®åˆ†æå’Œå¯è§†åŒ–
"""

from benchmark_visualizer import BenchmarkVisualizer
import pandas as pd

def demo_basic_usage():
    """åŸºç¡€ä½¿ç”¨æ¼”ç¤º"""
    print("=" * 60)
    print("ğŸ¯ vLLMåŸºå‡†æµ‹è¯•å¯è§†åŒ–å·¥å…· - åŸºç¡€ä½¿ç”¨æ¼”ç¤º")
    print("=" * 60)
    
    # åˆ›å»ºå¯è§†åŒ–å™¨å®ä¾‹
    visualizer = BenchmarkVisualizer()
    
    if visualizer.df is not None:
        # æ˜¾ç¤ºæ•°æ®æ‘˜è¦
        print(visualizer.get_data_summary())
        
        # ç”Ÿæˆå•ä¸ªå›¾è¡¨
        print("\nğŸ“Š ç”Ÿæˆååé‡åˆ†æå›¾...")
        visualizer.plot_throughput_analysis()
        
        print("\nâ±ï¸ ç”Ÿæˆå»¶è¿Ÿåˆ†æå›¾...")
        visualizer.plot_latency_analysis()
        
        print("\nğŸš€ ç”Ÿæˆäº¤äº’å¼ä»ªè¡¨æ¿...")
        visualizer.plot_interactive_dashboard()
        
        # ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š
        print("\nğŸ“‹ ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š...")
        report = visualizer.generate_performance_report()
        print(report)

def demo_custom_analysis():
    """è‡ªå®šä¹‰åˆ†ææ¼”ç¤º"""
    print("\n" + "=" * 60)
    print("ğŸ”¬ è‡ªå®šä¹‰åˆ†ææ¼”ç¤º")
    print("=" * 60)
    
    visualizer = BenchmarkVisualizer()
    
    if visualizer.df is not None:
        df = visualizer.df
        
        # è‡ªå®šä¹‰åˆ†æ1ï¼šæ‰¾å‡ºæœ€ä½³æ€§èƒ½é…ç½®
        print("\nğŸ† æœ€ä½³æ€§èƒ½é…ç½®åˆ†æ:")
        best_configs = df.nlargest(5, 'output_throughput')[
            ['config', 'output_throughput', 'mean_ttft_ms', 'max_concurrency']
        ]
        print(best_configs.to_string(index=False))
        
        # è‡ªå®šä¹‰åˆ†æ2ï¼šå¹¶å‘æ€§èƒ½æ•ˆç‡åˆ†æ
        print("\nâš¡ å¹¶å‘æ•ˆç‡åˆ†æ:")
        efficiency_analysis = df.groupby('max_concurrency').agg({
            'output_throughput': ['mean', 'std'],
            'efficiency': 'mean',
            'mean_ttft_ms': 'mean'
        }).round(2)
        print(efficiency_analysis)
        
        # è‡ªå®šä¹‰åˆ†æ3ï¼šè¾“å…¥è¾“å‡ºé•¿åº¦å½±å“åˆ†æ
        print("\nğŸ“ è¾“å…¥è¾“å‡ºé•¿åº¦å½±å“åˆ†æ:")
        length_analysis = df.groupby(['input_len', 'output_len']).agg({
            'output_throughput': 'mean',
            'mean_ttft_ms': 'mean',
            'count': 'size'
        }).round(2)
        print(length_analysis)

def demo_advanced_features():
    """é«˜çº§åŠŸèƒ½æ¼”ç¤º"""
    print("\n" + "=" * 60)
    print("ğŸš€ é«˜çº§åŠŸèƒ½æ¼”ç¤º")
    print("=" * 60)
    
    visualizer = BenchmarkVisualizer()
    
    if visualizer.df is not None:
        # ä¸€é”®ç”Ÿæˆæ‰€æœ‰å›¾è¡¨
        print("ğŸ“Š ä¸€é”®ç”Ÿæˆæ‰€æœ‰å¯è§†åŒ–å›¾è¡¨...")
        visualizer.generate_all_charts()
        
        print("\nâœ… é«˜çº§åŠŸèƒ½æ¼”ç¤ºå®Œæˆï¼")
        print(f"ğŸ“ æ‰€æœ‰æ–‡ä»¶å·²ä¿å­˜åˆ°: {visualizer.figures_dir}/")

def performance_insights():
    """æ€§èƒ½æ´å¯Ÿåˆ†æ"""
    print("\n" + "=" * 60)
    print("ğŸ’¡ æ€§èƒ½æ´å¯Ÿåˆ†æ")
    print("=" * 60)
    
    visualizer = BenchmarkVisualizer()
    
    if visualizer.df is not None:
        df = visualizer.df
        
        # è®¡ç®—å…³é”®æ´å¯Ÿ
        print("ğŸ“ˆ å…³é”®æ€§èƒ½æ´å¯Ÿ:")
        
        # 1. ååé‡ä¸å¹¶å‘æ•°çš„å…³ç³»
        throughput_corr = df['output_throughput'].corr(df['max_concurrency'])
        print(f"1. ååé‡ä¸å¹¶å‘æ•°ç›¸å…³æ€§: {throughput_corr:.3f}")
        
        if throughput_corr > 0.7:
            print("   âœ… å¼ºæ­£ç›¸å…³ - å¢åŠ å¹¶å‘æ•°å¯æœ‰æ•ˆæå‡ååé‡")
        elif throughput_corr > 0.3:
            print("   âš ï¸  ä¸­ç­‰ç›¸å…³ - å¢åŠ å¹¶å‘æ•°æœ‰ä¸€å®šæ•ˆæœä½†å¯èƒ½å­˜åœ¨ç“¶é¢ˆ")
        else:
            print("   âŒ å¼±ç›¸å…³ - ç»§ç»­å¢åŠ å¹¶å‘æ•°å¯èƒ½æ— æ•ˆæˆ–æœ‰å®³")
        
        # 2. å»¶è¿Ÿç¨³å®šæ€§åˆ†æ
        ttft_cv = df['mean_ttft_ms'].std() / df['mean_ttft_ms'].mean()
        print(f"\n2. TTFTå˜å¼‚ç³»æ•°: {ttft_cv:.3f}")
        
        if ttft_cv < 0.2:
            print("   âœ… å»¶è¿Ÿéå¸¸ç¨³å®š")
        elif ttft_cv < 0.5:
            print("   âš ï¸  å»¶è¿ŸåŸºæœ¬ç¨³å®š")
        else:
            print("   âŒ å»¶è¿Ÿæ³¢åŠ¨è¾ƒå¤§ï¼Œéœ€è¦ä¼˜åŒ–")
        
        # 3. æœ€ä¼˜é…ç½®æ¨è
        print(f"\n3. é…ç½®æ¨è:")
        
        # æ‰¾åˆ°æ•ˆç‡æœ€é«˜çš„é…ç½®
        best_efficiency_idx = df['efficiency'].idxmax()
        best_config = df.loc[best_efficiency_idx]
        
        print(f"   æ¨èé…ç½®: {best_config['config']}")
        print(f"   - å¹¶å‘æ•°: {best_config['max_concurrency']}")
        print(f"   - è¾“å…¥é•¿åº¦: {best_config['input_len']}")
        print(f"   - è¾“å‡ºé•¿åº¦: {best_config['output_len']}")
        print(f"   - æ•ˆç‡: {best_config['efficiency']:.2f} tokens/s per concurrency")
        print(f"   - ååé‡: {best_config['output_throughput']:.2f} tokens/s")
        print(f"   - TTFT: {best_config['mean_ttft_ms']:.2f} ms")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ vLLMåŸºå‡†æµ‹è¯•å¯è§†åŒ–å·¥å…·å®Œæ•´æ¼”ç¤º")
    print("=" * 80)
    
    try:
        # åŸºç¡€ä½¿ç”¨æ¼”ç¤º
        demo_basic_usage()
        
        # è‡ªå®šä¹‰åˆ†æ
        demo_custom_analysis()
        
        # æ€§èƒ½æ´å¯Ÿ
        performance_insights()
        
        # é«˜çº§åŠŸèƒ½ï¼ˆæ”¾åœ¨æœ€åï¼Œå› ä¸ºä¼šç”Ÿæˆæ‰€æœ‰å›¾è¡¨ï¼‰
        demo_advanced_features()
        
        print("\n" + "=" * 80)
        print("ğŸ‰ æ‰€æœ‰æ¼”ç¤ºå®Œæˆï¼")
        print("ğŸ’¡ æç¤ºï¼š")
        print("   - æ‰€æœ‰å›¾è¡¨æ–‡ä»¶ä¿å­˜åœ¨ 'figures/' ç›®å½•")
        print("   - å¯ä»¥å•ç‹¬è°ƒç”¨å„ä¸ªæ–¹æ³•è¿›è¡Œç‰¹å®šåˆ†æ")
        print("   - æ”¯æŒä¿å­˜ä¸ºPNGå’ŒHTMLæ ¼å¼")
        print("   - æŸ¥çœ‹ 'figures/performance_report.txt' è·å–è¯¦ç»†æŠ¥å‘Š")
        
    except Exception as e:
        print(f"âŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        print("ğŸ’¡ è¯·ç¡®ä¿å·²å®‰è£…æ‰€éœ€ä¾èµ–: pip install -r requirements.txt")
        print("ğŸ’¡ è¯·ç¡®ä¿å­˜åœ¨èšåˆç»“æœæ–‡ä»¶: python3 aggregate_result.py")

if __name__ == "__main__":
    main() 