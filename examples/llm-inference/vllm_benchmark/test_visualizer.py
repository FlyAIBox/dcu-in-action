#!/usr/bin/env python3
"""
å¯è§†åŒ–å·¥å…·æµ‹è¯•è„šæœ¬
éªŒè¯BenchmarkVisualizerç±»çš„å„é¡¹åŠŸèƒ½æ˜¯å¦æ­£å¸¸å·¥ä½œ
"""

import os
import sys
import pandas as pd
import numpy as np
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

def create_sample_data():
    """åˆ›å»ºç¤ºä¾‹æ•°æ®ç”¨äºæµ‹è¯•"""
    print("ğŸ“ åˆ›å»ºç¤ºä¾‹æ•°æ®...")
    
    # æ¨¡æ‹ŸåŸºå‡†æµ‹è¯•æ•°æ®
    np.random.seed(42)
    n_samples = 20
    
    data = {
        'date': [f"20250102-{str(10 + i).zfill(4)}00" for i in range(n_samples)],
        'backend': ['vllm'] * n_samples,
        'model_id': ['test-model'] * n_samples,
        'tokenizer_id': ['test-model'] * n_samples,
        'num_prompts': np.random.choice([10, 40, 80, 160, 320], n_samples),
        'request_rate': ['inf'] * n_samples,
        'burstiness': [1.0] * n_samples,
        'max_concurrency': np.random.choice([1, 4, 8, 16, 32, 48], n_samples),
        'duration': np.random.uniform(100, 2000, n_samples),
        'completed': np.random.choice([10, 40, 80, 160, 320], n_samples),
        'total_input_tokens': np.random.uniform(5000, 50000, n_samples),
        'total_output_tokens': np.random.uniform(5000, 50000, n_samples),
        'request_throughput': np.random.uniform(0.1, 1.5, n_samples),
        'request_goodput:': [''] * n_samples,
        'output_throughput': np.random.uniform(50, 400, n_samples),
        'total_token_throughput': np.random.uniform(100, 800, n_samples),
        'mean_ttft_ms': np.random.uniform(100, 5000, n_samples),
        'median_ttft_ms': np.random.uniform(100, 5000, n_samples),
        'std_ttft_ms': np.random.uniform(10, 1000, n_samples),
        'p99_ttft_ms': np.random.uniform(200, 8000, n_samples),
        'mean_tpot_ms': np.random.uniform(30, 100, n_samples),
        'median_tpot_ms': np.random.uniform(30, 100, n_samples),
        'std_tpot_ms': np.random.uniform(1, 50, n_samples),
        'p99_tpot_ms': np.random.uniform(40, 150, n_samples),
        'mean_itl_ms': np.random.uniform(30, 100, n_samples),
        'median_itl_ms': np.random.uniform(30, 100, n_samples),
        'std_itl_ms': np.random.uniform(1, 50, n_samples),
        'p99_itl_ms': np.random.uniform(40, 150, n_samples),
        'mean_e2el_ms': np.random.uniform(5000, 50000, n_samples),
        'median_e2el_ms': np.random.uniform(5000, 50000, n_samples),
        'std_e2el_ms': np.random.uniform(100, 5000, n_samples),
        'p99_e2el_ms': np.random.uniform(10000, 80000, n_samples),
        'input_len': np.random.choice([256, 512, 1024, 2048], n_samples),
        'output_len': np.random.choice([256, 512, 1024, 2048], n_samples),
        'filename': [f'test_run_{i}.json' for i in range(n_samples)]
    }
    
    df = pd.DataFrame(data)
    
    # ç¡®ä¿resultsç›®å½•å­˜åœ¨
    os.makedirs('results', exist_ok=True)
    
    # ä¿å­˜æµ‹è¯•æ•°æ®
    test_csv = 'results/test_aggregate_results.csv'
    df.to_csv(test_csv, index=False)
    
    print(f"âœ… ç¤ºä¾‹æ•°æ®å·²åˆ›å»º: {test_csv}")
    return test_csv

def test_dependencies():
    """æµ‹è¯•ä¾èµ–åŒ…"""
    print("ğŸ“¦ æµ‹è¯•ä¾èµ–åŒ…...")
    
    required_packages = [
        'pandas',
        'numpy', 
        'matplotlib',
        'seaborn'
    ]
    
    missing_packages = []
    
    for package in required_packages:
        try:
            __import__(package)
            print(f"  âœ… {package}")
        except ImportError:
            print(f"  âŒ {package} - æœªå®‰è£…")
            missing_packages.append(package)
    
    # æµ‹è¯•plotly
    try:
        import plotly.express as px
        import plotly.graph_objects as go
        print(f"  âœ… plotly")
    except ImportError:
        print(f"  âŒ plotly - æœªå®‰è£…")
        missing_packages.append('plotly')
    
    if missing_packages:
        print(f"\nâŒ ç¼ºå°‘ä¾èµ–åŒ…: {missing_packages}")
        print("è¯·è¿è¡Œ: pip install " + " ".join(missing_packages))
        return False
    
    print("âœ… æ‰€æœ‰ä¾èµ–åŒ…æ­£å¸¸")
    return True

def test_visualizer_basic():
    """æµ‹è¯•åŸºç¡€åŠŸèƒ½"""
    print("\nğŸ”§ æµ‹è¯•åŸºç¡€åŠŸèƒ½...")
    
    try:
        from benchmark_visualizer import BenchmarkVisualizer
        
        # åˆ›å»ºç¤ºä¾‹æ•°æ®
        test_csv = create_sample_data()
        
        # åˆå§‹åŒ–å¯è§†åŒ–å™¨
        visualizer = BenchmarkVisualizer(csv_path=test_csv)
        
        if visualizer.df is None:
            print("âŒ æ•°æ®åŠ è½½å¤±è´¥")
            return False
        
        print(f"âœ… æ•°æ®åŠ è½½æˆåŠŸ: {len(visualizer.df)} æ¡è®°å½•")
        return True
        
    except Exception as e:
        print(f"âŒ åŸºç¡€åŠŸèƒ½æµ‹è¯•å¤±è´¥: {e}")
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ§ª vLLMåŸºå‡†æµ‹è¯•å¯è§†åŒ–å·¥å…· - å¿«é€Ÿæµ‹è¯•")
    print("=" * 50)
    
    tests = [
        ("ä¾èµ–åŒ…æ£€æŸ¥", test_dependencies),
        ("åŸºç¡€åŠŸèƒ½", test_visualizer_basic)
    ]
    
    passed = 0
    total = len(tests)
    
    for test_name, test_func in tests:
        print(f"\n{test_name}:")
        
        try:
            if test_func():
                print(f"âœ… {test_name} - é€šè¿‡")
                passed += 1
            else:
                print(f"âŒ {test_name} - å¤±è´¥")
        except Exception as e:
            print(f"âŒ {test_name} - å¼‚å¸¸: {e}")
    
    print(f"\nğŸ æµ‹è¯•å®Œæˆ: {passed}/{total} é€šè¿‡")
    
    if passed == total:
        print("ğŸ‰ åŸºç¡€æµ‹è¯•é€šè¿‡ï¼å¯è§†åŒ–å·¥å…·å·²å°±ç»ªã€‚")
        print("\nğŸ’¡ ä½¿ç”¨æç¤º:")
        print("   python3 visualize.py              # ç”Ÿæˆæ‰€æœ‰å›¾è¡¨")
        print("   python3 example_usage.py          # æŸ¥çœ‹ä½¿ç”¨ç¤ºä¾‹")
    else:
        print(f"âš ï¸ {total - passed} ä¸ªæµ‹è¯•å¤±è´¥ï¼Œè¯·å®‰è£…ä¾èµ–åŒ…ã€‚")

if __name__ == "__main__":
    main() 