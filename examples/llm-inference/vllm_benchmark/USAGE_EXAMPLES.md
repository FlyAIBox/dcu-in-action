# ğŸ¯ ä½¿ç”¨ç¤ºä¾‹å’Œæœ€ä½³å®è·µ

## ğŸ“‹ å¸¸ç”¨æµ‹è¯•åœºæ™¯ç¤ºä¾‹

### 1. å¿«é€ŸåŠŸèƒ½éªŒè¯æµ‹è¯•

**ç›®æ ‡**: éªŒè¯ç³»ç»ŸåŸºæœ¬åŠŸèƒ½æ˜¯å¦æ­£å¸¸

```bash
# æœ€ç®€å•çš„æµ‹è¯•å‘½ä»¤
python benchmark_serving.py \
    --backend vllm \
    --model /path/to/your/model \
    --dataset-name random \
    --num-prompts 5 \
    --random-input-len 50 \
    --random-output-len 20

# é¢„æœŸç»“æœ: 5ä¸ªè¯·æ±‚å…¨éƒ¨æˆåŠŸï¼Œè·å¾—åŸºç¡€æ€§èƒ½æ•°æ®
```

**é€‚ç”¨åœºæ™¯**:
- æ–°éƒ¨ç½²æœåŠ¡çš„åŠŸèƒ½éªŒè¯
- ä»£ç ä¿®æ”¹åçš„å›å½’æµ‹è¯•
- å¿«é€Ÿæ£€æŸ¥æœåŠ¡çŠ¶æ€

### 2. æ€§èƒ½åŸºå‡†æµ‹è¯•

**ç›®æ ‡**: å»ºç«‹ç³»ç»Ÿæ€§èƒ½åŸºå‡†çº¿

```bash
# æ ‡å‡†åŸºå‡†æµ‹è¯•
python benchmark_serving.py \
    --backend vllm \
    --model /path/to/your/model \
    --dataset-name random \
    --num-prompts 1000 \
    --random-input-len 512 \
    --random-output-len 128 \
    --save-result \
    --result-dir ./benchmarks \
    --metadata model_version=v1.0 hardware=8xDCU

# é¢„æœŸç»“æœ: è·å¾—1000ä¸ªè¯·æ±‚çš„è¯¦ç»†æ€§èƒ½æ•°æ®
```

**å…³é”®å‚æ•°è¯´æ˜**:
- `--num-prompts 1000`: è¶³å¤Ÿçš„æ ·æœ¬é‡ç¡®ä¿ç»Ÿè®¡æ„ä¹‰
- `--save-result`: ä¿å­˜è¯¦ç»†ç»“æœç”¨äºåç»­åˆ†æ
- `--metadata`: æ·»åŠ å…ƒæ•°æ®ä¾¿äºç»“æœç®¡ç†

### 3. å¹¶å‘å‹åŠ›æµ‹è¯•

**ç›®æ ‡**: æµ‹è¯•ç³»ç»Ÿåœ¨é«˜å¹¶å‘ä¸‹çš„è¡¨ç°

```bash
# æ¸è¿›å¼å¹¶å‘æµ‹è¯•
for concurrency in 10 20 50 100 200; do
    echo "Testing with concurrency: $concurrency"
    python benchmark_serving.py \
        --backend vllm \
        --model /path/to/your/model \
        --dataset-name random \
        --num-prompts 500 \
        --request-rate 50 \
        --max-concurrency $concurrency \
        --random-input-len 256 \
        --random-output-len 64 \
        --save-result \
        --result-filename "concurrency_${concurrency}.json"
done

# åˆ†æä¸åŒå¹¶å‘åº¦ä¸‹çš„æ€§èƒ½å˜åŒ–
```

**åˆ†æè¦ç‚¹**:
- è§‚å¯Ÿååé‡éšå¹¶å‘åº¦çš„å˜åŒ–
- æ‰¾åˆ°æ€§èƒ½æ‹ç‚¹ (æœ€ä¼˜å¹¶å‘åº¦)
- ç›‘æ§ç³»ç»Ÿèµ„æºä½¿ç”¨æƒ…å†µ

### 4. çœŸå®åœºæ™¯æ¨¡æ‹Ÿæµ‹è¯•

**ç›®æ ‡**: ä½¿ç”¨çœŸå®æ•°æ®æ¨¡æ‹Ÿç”¨æˆ·ä½¿ç”¨åœºæ™¯

```bash
# ä¸‹è½½ShareGPTæ•°æ®é›†
wget https://huggingface.co/datasets/anon8231489123/ShareGPT_Vicuna_unfiltered/resolve/main/ShareGPT_V3_unfiltered_cleaned_split.json

# çœŸå®åœºæ™¯æµ‹è¯•
python benchmark_serving.py \
    --backend vllm \
    --model /path/to/your/model \
    --dataset-name sharegpt \
    --dataset-path ShareGPT_V3_unfiltered_cleaned_split.json \
    --num-prompts 200 \
    --request-rate 5 \
    --save-result \
    --save-detailed

# é¢„æœŸç»“æœ: æ›´æ¥è¿‘çœŸå®ä½¿ç”¨åœºæ™¯çš„æ€§èƒ½æ•°æ®
```

**ä¼˜åŠ¿**:
- è¾“å…¥é•¿åº¦åˆ†å¸ƒæ›´çœŸå®
- å¯¹è¯å†…å®¹æ›´è´´è¿‘å®é™…ä½¿ç”¨
- èƒ½å‘ç°åˆæˆæ•°æ®æµ‹è¯•ä¸­é—æ¼çš„é—®é¢˜

### 5. æœåŠ¡è´¨é‡ (SLO) æµ‹è¯•

**ç›®æ ‡**: éªŒè¯ç³»ç»Ÿæ˜¯å¦æ»¡è¶³æœåŠ¡çº§åˆ«ç›®æ ‡

```bash
# SLOæµ‹è¯•
python benchmark_serving.py \
    --backend vllm \
    --model /path/to/your/model \
    --dataset-name random \
    --num-prompts 1000 \
    --request-rate 20 \
    --goodput ttft:100 tpot:50 e2el:2000 \
    --random-input-len 512 \
    --random-output-len 128

# é¢„æœŸç»“æœ: è·å¾—æ»¡è¶³SLOçš„è¯·æ±‚æ¯”ä¾‹ (goodput)
```

**SLOé…ç½®è¯´æ˜**:
- `ttft:100`: é¦–æ¬¡å“åº”æ—¶é—´ < 100ms
- `tpot:50`: æ¯tokenç”Ÿæˆæ—¶é—´ < 50ms  
- `e2el:2000`: ç«¯åˆ°ç«¯å»¶è¿Ÿ < 2000ms

## ğŸ† æœ€ä½³å®è·µæŒ‡å—

### 1. æµ‹è¯•ç¯å¢ƒå‡†å¤‡

#### ç¡¬ä»¶ç¯å¢ƒ
```bash
# æ£€æŸ¥DCUçŠ¶æ€
rocm-smi

# è®¾ç½®DCUç¯å¢ƒ
export HIP_VISIBLE_DEVICES=0,1,2,3,4,5,6,7
export NCCL_MAX_NCHANNELS=16
export NCCL_P2P_LEVEL=SYS

# æ£€æŸ¥å†…å­˜å’Œå­˜å‚¨
free -h
df -h
```

#### è½¯ä»¶ç¯å¢ƒ
```bash
# åˆ›å»ºç‹¬ç«‹çš„æµ‹è¯•ç¯å¢ƒ
conda create -n benchmark python=3.10
conda activate benchmark

# å®‰è£…ä¾èµ–
pip install -r requirements.txt

# éªŒè¯å®‰è£…
python -c "import vllm; print('vLLM installed successfully')"
```

### 2. æµ‹è¯•ç­–ç•¥è®¾è®¡

#### åˆ†å±‚æµ‹è¯•ç­–ç•¥
```
1. å†’çƒŸæµ‹è¯• (Smoke Test)
   â””â”€â”€ 5-10ä¸ªè¯·æ±‚ï¼ŒéªŒè¯åŸºæœ¬åŠŸèƒ½

2. åŠŸèƒ½æµ‹è¯• (Functional Test)  
   â””â”€â”€ 100-200ä¸ªè¯·æ±‚ï¼ŒéªŒè¯å„é¡¹åŠŸèƒ½

3. æ€§èƒ½æµ‹è¯• (Performance Test)
   â””â”€â”€ 1000+è¯·æ±‚ï¼Œå»ºç«‹æ€§èƒ½åŸºå‡†

4. å‹åŠ›æµ‹è¯• (Stress Test)
   â””â”€â”€ é«˜å¹¶å‘ã€é•¿æ—¶é—´æµ‹è¯•

5. ç¨³å®šæ€§æµ‹è¯• (Stability Test)
   â””â”€â”€ 24å°æ—¶æŒç»­è¿è¡Œæµ‹è¯•
```

#### å‚æ•°é€‰æ‹©åŸåˆ™
```bash
# è¾“å…¥é•¿åº¦é€‰æ‹©
--random-input-len 512    # çŸ­æ–‡æœ¬åœºæ™¯
--random-input-len 1024   # ä¸­ç­‰é•¿åº¦åœºæ™¯  
--random-input-len 2048   # é•¿æ–‡æœ¬åœºæ™¯

# è¾“å‡ºé•¿åº¦é€‰æ‹©
--random-output-len 64    # ç®€çŸ­å›å¤
--random-output-len 128   # æ ‡å‡†å›å¤
--random-output-len 256   # è¯¦ç»†å›å¤

# è¯·æ±‚æ•°é‡é€‰æ‹©
--num-prompts 10          # å¿«é€ŸéªŒè¯
--num-prompts 100         # åŠŸèƒ½æµ‹è¯•
--num-prompts 1000        # æ€§èƒ½åŸºå‡†
--num-prompts 10000       # å‹åŠ›æµ‹è¯•
```

### 3. ä½¿ç”¨combos.yamlé…ç½®æ–‡ä»¶

#### åŸºç¡€é…ç½®ç¤ºä¾‹
```yaml
# combos.yaml
model: "/path/to/your/model"
base_url: "http://localhost:8000"
tokenizer: "/path/to/your/model"

# æµ‹è¯•å‚æ•°ç»„åˆ
input_len: [256, 512, 1024]
output_len: [64, 128, 256]
concurrency: [1, 5, 10, 20, 50]
prompt: [100, 500, 1000]
```

#### è¿è¡Œæ‰¹é‡æµ‹è¯•
```bash
# ä½¿ç”¨é…ç½®æ–‡ä»¶è¿è¡Œæ‰¹é‡æµ‹è¯•
python run_sweep.py

# èšåˆç»“æœ
python aggregate_result.py

# ç”Ÿæˆå¯è§†åŒ–æŠ¥å‘Š
python visualize.py --all
```

### 4. ç»“æœåˆ†æå’Œå¯è§†åŒ–

#### ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š
```bash
# ç”Ÿæˆæ‰€æœ‰å›¾è¡¨
python visualize.py

# ç”Ÿæˆç‰¹å®šåˆ†æ
python visualize.py --throughput    # ååé‡åˆ†æ
python visualize.py --latency       # å»¶è¿Ÿåˆ†æ
python visualize.py --interactive   # äº¤äº’å¼ä»ªè¡¨æ¿
python visualize.py --report        # æ€§èƒ½æŠ¥å‘Š
```

#### ç¼–ç¨‹æ¥å£ä½¿ç”¨
```python
from benchmark_visualizer import BenchmarkVisualizer

# åˆ›å»ºå¯è§†åŒ–å™¨
visualizer = BenchmarkVisualizer("results/aggregate_results.csv")

# ç”Ÿæˆç‰¹å®šå›¾è¡¨
visualizer.plot_throughput_analysis()
visualizer.plot_latency_analysis()

# è·å–æ€§èƒ½æŠ¥å‘Š
report = visualizer.generate_performance_report()
print(report)

# ä¸€é”®ç”Ÿæˆæ‰€æœ‰å›¾è¡¨
visualizer.generate_all_charts()
```

## ğŸ”§ å¸¸è§é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆ

### é—®é¢˜1: è¿æ¥è¶…æ—¶
```bash
# ç—‡çŠ¶: requests.exceptions.ConnectTimeout
# åŸå› : vLLMæœåŠ¡æœªå¯åŠ¨æˆ–ç«¯å£ä¸æ­£ç¡®
# è§£å†³: 
curl http://localhost:8000/v1/models  # éªŒè¯æœåŠ¡çŠ¶æ€
netstat -tlnp | grep 8000            # æ£€æŸ¥ç«¯å£å ç”¨
```

### é—®é¢˜2: å†…å­˜ä¸è¶³ (OOM)
```bash
# ç—‡çŠ¶: CUDA out of memory
# åŸå› : æ¨¡å‹å¤ªå¤§æˆ–å¹¶å‘åº¦è¿‡é«˜
# è§£å†³:
--gpu-memory-utilization 0.8         # é™ä½GPUå†…å­˜ä½¿ç”¨ç‡
--max-concurrency 10                 # é™åˆ¶å¹¶å‘æ•°
--max-model-len 2048                 # å‡å°‘æœ€å¤§åºåˆ—é•¿åº¦
```

### é—®é¢˜3: æ€§èƒ½å¼‚å¸¸æ³¢åŠ¨
```bash
# ç—‡çŠ¶: æ€§èƒ½æŒ‡æ ‡ä¸ç¨³å®šï¼Œæ–¹å·®å¾ˆå¤§
# åŸå› : ç³»ç»Ÿè´Ÿè½½ã€ç½‘ç»œæŠ–åŠ¨ã€èµ„æºç«äº‰
# è§£å†³:
# 1. ç³»ç»Ÿé¢„çƒ­
for i in {1..10}; do
    curl -s http://localhost:8000/v1/completions \
        -d '{"model":"test","prompt":"hello","max_tokens":10}' \
        -H "Content-Type: application/json" > /dev/null
done

# 2. ç›‘æ§ç³»ç»Ÿèµ„æº
htop &
rocm-smi -l 1 &

# 3. å¤šæ¬¡æµ‹è¯•å–å¹³å‡å€¼
for i in {1..5}; do
    python benchmark_serving.py ... --result-filename "run_${i}.json"
done
```

## ğŸ¯ ä¸åŒä¸šåŠ¡åœºæ™¯çš„é…ç½®å»ºè®®

### åœ¨çº¿å®¢æœç³»ç»Ÿ
```bash
# ç‰¹ç‚¹: ä¸­ç­‰å¹¶å‘ï¼Œå“åº”è¦æ±‚å¿«
python benchmark_serving.py \
    --max-concurrency 50 \
    --request-rate 20 \
    --random-input-len 256 \
    --random-output-len 128 \
    --goodput ttft:100 tpot:30
```

### å†…å®¹ç”Ÿæˆå¹³å°
```bash
# ç‰¹ç‚¹: é«˜å¹¶å‘ï¼Œå¯æ¥å—è¾ƒé•¿å»¶è¿Ÿ
python benchmark_serving.py \
    --max-concurrency 200 \
    --request-rate 100 \
    --random-input-len 512 \
    --random-output-len 512 \
    --goodput ttft:200 tpot:100
```

### ä»£ç åŠ©æ‰‹å·¥å…·
```bash
# ç‰¹ç‚¹: ä¸­ä½å¹¶å‘ï¼Œè¾“å…¥è¾“å‡ºéƒ½è¾ƒé•¿
python benchmark_serving.py \
    --max-concurrency 20 \
    --request-rate 10 \
    --random-input-len 1024 \
    --random-output-len 256 \
    --goodput ttft:150 tpot:50
```

é€šè¿‡è¿™äº›ç¤ºä¾‹å’Œæœ€ä½³å®è·µï¼Œä½ å¯ä»¥ç³»ç»Ÿæ€§åœ°è¿›è¡Œå¤§æ¨¡å‹æ¨ç†æ€§èƒ½æµ‹è¯•ï¼Œè·å¾—å¯é çš„æ€§èƒ½æ•°æ®ï¼Œå¹¶æŒç»­ä¼˜åŒ–ç³»ç»Ÿæ€§èƒ½ã€‚
