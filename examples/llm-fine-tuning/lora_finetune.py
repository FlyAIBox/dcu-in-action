#!/usr/bin/env python3
"""
åŸºäºLoRAçš„å¤§æ¨¡å‹å¾®è°ƒç¤ºä¾‹
æ”¯æŒæµ·å…‰DCUï¼Œä½¿ç”¨PEFTåº“å®ç°é«˜æ•ˆå‚æ•°å¾®è°ƒ
"""

import os
import json
import torch
import argparse
from dataclasses import dataclass, field
from typing import Optional, Dict, List, Union
from pathlib import Path

from transformers import (
    AutoTokenizer,
    AutoModelForCausalLM,
    TrainingArguments,
    Trainer,
    DataCollatorForSeq2Seq,
    BitsAndBytesConfig
)
from peft import (
    LoraConfig,
    get_peft_model,
    TaskType,
    prepare_model_for_kbit_training
)
from datasets import Dataset, load_dataset
import wandb

@dataclass
class ModelArguments:
    """æ¨¡å‹ç›¸å…³å‚æ•°"""
    model_name_or_path: str = field(
        default="baichuan-inc/Baichuan2-7B-Chat",
        metadata={"help": "é¢„è®­ç»ƒæ¨¡å‹åç§°æˆ–è·¯å¾„"}
    )
    cache_dir: Optional[str] = field(
        default=None,
        metadata={"help": "æ¨¡å‹ç¼“å­˜ç›®å½•"}
    )
    trust_remote_code: bool = field(
        default=True,
        metadata={"help": "æ˜¯å¦ä¿¡ä»»è¿œç¨‹ä»£ç "}
    )
    use_auth_token: bool = field(
        default=False,
        metadata={"help": "æ˜¯å¦ä½¿ç”¨è®¤è¯ä»¤ç‰Œ"}
    )

@dataclass
class DataArguments:
    """æ•°æ®ç›¸å…³å‚æ•°"""
    dataset_path: str = field(
        default="./data/alpaca_data.json",
        metadata={"help": "è®­ç»ƒæ•°æ®è·¯å¾„"}
    )
    validation_split_percentage: int = field(
        default=5,
        metadata={"help": "éªŒè¯é›†åˆ†å‰²æ¯”ä¾‹"}
    )
    max_train_samples: Optional[int] = field(
        default=None,
        metadata={"help": "æœ€å¤§è®­ç»ƒæ ·æœ¬æ•°"}
    )
    max_eval_samples: Optional[int] = field(
        default=None,
        metadata={"help": "æœ€å¤§è¯„ä¼°æ ·æœ¬æ•°"}
    )
    overwrite_cache: bool = field(
        default=False,
        metadata={"help": "æ˜¯å¦è¦†ç›–ç¼“å­˜"}
    )
    preprocessing_num_workers: Optional[int] = field(
        default=None,
        metadata={"help": "æ•°æ®é¢„å¤„ç†è¿›ç¨‹æ•°"}
    )

@dataclass
class LoRAArguments:
    """LoRAç›¸å…³å‚æ•°"""
    lora_rank: int = field(
        default=8,
        metadata={"help": "LoRA rank"}
    )
    lora_alpha: int = field(
        default=16,
        metadata={"help": "LoRA alpha"}
    )
    lora_dropout: float = field(
        default=0.1,
        metadata={"help": "LoRA dropout"}
    )
    lora_target_modules: Optional[str] = field(
        default="q_proj,v_proj",
        metadata={"help": "LoRAç›®æ ‡æ¨¡å—"}
    )
    lora_bias: str = field(
        default="none",
        metadata={"help": "LoRA biasç±»å‹"}
    )
    use_rslora: bool = field(
        default=False,
        metadata={"help": "æ˜¯å¦ä½¿ç”¨RSLoRA"}
    )

@dataclass
class QuantizationArguments:
    """é‡åŒ–ç›¸å…³å‚æ•°"""
    use_4bit: bool = field(
        default=True,
        metadata={"help": "æ˜¯å¦ä½¿ç”¨4bité‡åŒ–"}
    )
    bnb_4bit_compute_dtype: str = field(
        default="float16",
        metadata={"help": "4bitè®¡ç®—æ•°æ®ç±»å‹"}
    )
    bnb_4bit_quant_type: str = field(
        default="nf4",
        metadata={"help": "4bité‡åŒ–ç±»å‹"}
    )
    bnb_4bit_use_double_quant: bool = field(
        default=False,
        metadata={"help": "æ˜¯å¦ä½¿ç”¨åŒé‡é‡åŒ–"}
    )

class LoRATrainer:
    """LoRAå¾®è°ƒè®­ç»ƒå™¨"""
    
    def __init__(
        self,
        model_args: ModelArguments,
        data_args: DataArguments,
        training_args: TrainingArguments,
        lora_args: LoRAArguments,
        quant_args: QuantizationArguments
    ):
        self.model_args = model_args
        self.data_args = data_args
        self.training_args = training_args
        self.lora_args = lora_args
        self.quant_args = quant_args
        
        self.tokenizer = None
        self.model = None
        self.train_dataset = None
        self.eval_dataset = None
    
    def load_tokenizer(self):
        """åŠ è½½åˆ†è¯å™¨"""
        print("ğŸ”„ åŠ è½½åˆ†è¯å™¨...")
        
        self.tokenizer = AutoTokenizer.from_pretrained(
            self.model_args.model_name_or_path,
            cache_dir=self.model_args.cache_dir,
            use_fast=True,
            trust_remote_code=self.model_args.trust_remote_code,
            use_auth_token=self.model_args.use_auth_token
        )
        
        # è®¾ç½®ç‰¹æ®Štoken
        if self.tokenizer.pad_token is None:
            self.tokenizer.pad_token = self.tokenizer.eos_token
        
        print(f"âœ… åˆ†è¯å™¨åŠ è½½å®Œæˆ: {len(self.tokenizer)} tokens")
    
    def load_model(self):
        """åŠ è½½æ¨¡å‹"""
        print("ğŸ”„ åŠ è½½æ¨¡å‹...")
        
        # é‡åŒ–é…ç½®
        if self.quant_args.use_4bit:
            quantization_config = BitsAndBytesConfig(
                load_in_4bit=True,
                bnb_4bit_compute_dtype=getattr(torch, self.quant_args.bnb_4bit_compute_dtype),
                bnb_4bit_use_double_quant=self.quant_args.bnb_4bit_use_double_quant,
                bnb_4bit_quant_type=self.quant_args.bnb_4bit_quant_type
            )
        else:
            quantization_config = None
        
        # åŠ è½½æ¨¡å‹
        self.model = AutoModelForCausalLM.from_pretrained(
            self.model_args.model_name_or_path,
            cache_dir=self.model_args.cache_dir,
            quantization_config=quantization_config,
            device_map="auto",
            trust_remote_code=self.model_args.trust_remote_code,
            use_auth_token=self.model_args.use_auth_token,
            torch_dtype=torch.float16 if not quantization_config else None
        )
        
        # å‡†å¤‡é‡åŒ–è®­ç»ƒ
        if quantization_config:
            self.model = prepare_model_for_kbit_training(self.model)
        
        print(f"âœ… æ¨¡å‹åŠ è½½å®Œæˆ: {self.model_args.model_name_or_path}")
        
        # æ‰“å°æ¨¡å‹ä¿¡æ¯
        total_params = sum(p.numel() for p in self.model.parameters())
        print(f"ğŸ“Š æ¨¡å‹æ€»å‚æ•°é‡: {total_params:,}")
    
    def setup_lora(self):
        """è®¾ç½®LoRAé…ç½®"""
        print("ğŸ”„ é…ç½®LoRA...")
        
        # LoRAé…ç½®
        lora_config = LoraConfig(
            task_type=TaskType.CAUSAL_LM,
            r=self.lora_args.lora_rank,
            lora_alpha=self.lora_args.lora_alpha,
            lora_dropout=self.lora_args.lora_dropout,
            target_modules=self.lora_args.lora_target_modules.split(","),
            bias=self.lora_args.lora_bias,
            use_rslora=self.lora_args.use_rslora
        )
        
        # åº”ç”¨LoRA
        self.model = get_peft_model(self.model, lora_config)
        
        # æ‰“å°å¯è®­ç»ƒå‚æ•°
        trainable_params = sum(p.numel() for p in self.model.parameters() if p.requires_grad)
        total_params = sum(p.numel() for p in self.model.parameters())
        
        print(f"âœ… LoRAé…ç½®å®Œæˆ")
        print(f"ğŸ“Š å¯è®­ç»ƒå‚æ•°: {trainable_params:,} ({trainable_params/total_params*100:.2f}%)")
        print(f"ğŸ“Š æ€»å‚æ•°é‡: {total_params:,}")
    
    def load_dataset(self):
        """åŠ è½½å’Œé¢„å¤„ç†æ•°æ®é›†"""
        print("ğŸ”„ åŠ è½½æ•°æ®é›†...")
        
        # åŠ è½½æ•°æ®
        if self.data_args.dataset_path.endswith('.json'):
            with open(self.data_args.dataset_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
        else:
            data = load_dataset(self.data_args.dataset_path)
            data = data['train']
        
        # è½¬æ¢ä¸ºDatasetæ ¼å¼
        if isinstance(data, list):
            dataset = Dataset.from_list(data)
        else:
            dataset = data
        
        # æ•°æ®é¢„å¤„ç†å‡½æ•°
        def preprocess_function(examples):
            model_inputs = {"input_ids": [], "attention_mask": [], "labels": []}
            
            for i in range(len(examples['instruction'])):
                instruction = examples['instruction'][i]
                input_text = examples.get('input', [''])[i]
                output_text = examples['output'][i]
                
                # æ„å»ºå®Œæ•´çš„è¾“å…¥
                if input_text:
                    full_prompt = f"### æŒ‡ä»¤:\n{instruction}\n\n### è¾“å…¥:\n{input_text}\n\n### å›ç­”:\n{output_text}"
                else:
                    full_prompt = f"### æŒ‡ä»¤:\n{instruction}\n\n### å›ç­”:\n{output_text}"
                
                # åˆ†è¯
                tokenized = self.tokenizer(
                    full_prompt,
                    truncation=True,
                    padding=False,
                    max_length=2048,
                    return_tensors=None
                )
                
                model_inputs["input_ids"].append(tokenized["input_ids"])
                model_inputs["attention_mask"].append(tokenized["attention_mask"])
                model_inputs["labels"].append(tokenized["input_ids"].copy())
            
            return model_inputs
        
        # åº”ç”¨é¢„å¤„ç†
        processed_dataset = dataset.map(
            preprocess_function,
            batched=True,
            num_proc=self.data_args.preprocessing_num_workers,
            remove_columns=dataset.column_names,
            desc="Preprocessing dataset"
        )
        
        # åˆ†å‰²è®­ç»ƒé›†å’ŒéªŒè¯é›†
        if self.data_args.validation_split_percentage > 0:
            split_dataset = processed_dataset.train_test_split(
                test_size=self.data_args.validation_split_percentage / 100
            )
            self.train_dataset = split_dataset['train']
            self.eval_dataset = split_dataset['test']
        else:
            self.train_dataset = processed_dataset
            self.eval_dataset = None
        
        # é™åˆ¶æ ·æœ¬æ•°é‡
        if self.data_args.max_train_samples and len(self.train_dataset) > self.data_args.max_train_samples:
            self.train_dataset = self.train_dataset.select(range(self.data_args.max_train_samples))
        
        if self.eval_dataset and self.data_args.max_eval_samples and len(self.eval_dataset) > self.data_args.max_eval_samples:
            self.eval_dataset = self.eval_dataset.select(range(self.data_args.max_eval_samples))
        
        print(f"âœ… æ•°æ®é›†åŠ è½½å®Œæˆ")
        print(f"ğŸ“Š è®­ç»ƒæ ·æœ¬: {len(self.train_dataset)}")
        if self.eval_dataset:
            print(f"ğŸ“Š éªŒè¯æ ·æœ¬: {len(self.eval_dataset)}")
    
    def train(self):
        """å¼€å§‹è®­ç»ƒ"""
        print("ğŸš€ å¼€å§‹LoRAå¾®è°ƒ...")
        
        # æ•°æ®æ•´ç†å™¨
        data_collator = DataCollatorForSeq2Seq(
            tokenizer=self.tokenizer,
            model=self.model,
            padding=True,
            return_tensors="pt"
        )
        
        # åˆ›å»ºè®­ç»ƒå™¨
        trainer = Trainer(
            model=self.model,
            args=self.training_args,
            train_dataset=self.train_dataset,
            eval_dataset=self.eval_dataset,
            tokenizer=self.tokenizer,
            data_collator=data_collator
        )
        
        # è®­ç»ƒå‰å›è°ƒ
        if self.training_args.do_train:
            # å¼€å§‹è®­ç»ƒ
            train_result = trainer.train()
            
            # ä¿å­˜æ¨¡å‹
            trainer.save_model()
            
            # ä¿å­˜è®­ç»ƒç»“æœ
            trainer.log_metrics("train", train_result.metrics)
            trainer.save_metrics("train", train_result.metrics)
            trainer.save_state()
        
        # è¯„ä¼°
        if self.training_args.do_eval and self.eval_dataset:
            print("ğŸ“Š å¼€å§‹è¯„ä¼°...")
            eval_result = trainer.evaluate()
            trainer.log_metrics("eval", eval_result)
            trainer.save_metrics("eval", eval_result)
        
        print("ğŸ‰ è®­ç»ƒå®Œæˆï¼")
    
    def save_lora_model(self, output_dir: str):
        """ä¿å­˜LoRAæ¨¡å‹"""
        print(f"ğŸ’¾ ä¿å­˜LoRAæ¨¡å‹åˆ°: {output_dir}")
        
        # ä¿å­˜LoRAæƒé‡
        self.model.save_pretrained(output_dir)
        
        # ä¿å­˜åˆ†è¯å™¨
        self.tokenizer.save_pretrained(output_dir)
        
        # ä¿å­˜é…ç½®ä¿¡æ¯
        config = {
            "base_model": self.model_args.model_name_or_path,
            "lora_rank": self.lora_args.lora_rank,
            "lora_alpha": self.lora_args.lora_alpha,
            "lora_dropout": self.lora_args.lora_dropout,
            "target_modules": self.lora_args.lora_target_modules,
            "task_type": "CAUSAL_LM"
        }
        
        with open(f"{output_dir}/lora_config.json", "w") as f:
            json.dump(config, f, indent=2)
        
        print("âœ… æ¨¡å‹ä¿å­˜å®Œæˆ")

def create_sample_data():
    """åˆ›å»ºç¤ºä¾‹è®­ç»ƒæ•°æ®"""
    sample_data = [
        {
            "instruction": "è§£é‡Šä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ",
            "input": "",
            "output": "æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œå®ƒä½¿è®¡ç®—æœºèƒ½å¤Ÿåœ¨æ²¡æœ‰æ˜ç¡®ç¼–ç¨‹çš„æƒ…å†µä¸‹å­¦ä¹ å’Œæ”¹è¿›ã€‚é€šè¿‡ç®—æ³•å’Œç»Ÿè®¡æ¨¡å‹ï¼Œæœºå™¨å­¦ä¹ ç³»ç»Ÿå¯ä»¥ä»æ•°æ®ä¸­è¯†åˆ«æ¨¡å¼ï¼Œå¹¶åŸºäºè¿™äº›æ¨¡å¼åšå‡ºé¢„æµ‹æˆ–å†³ç­–ã€‚"
        },
        {
            "instruction": "è®¡ç®—ä¸¤ä¸ªæ•°çš„å’Œ",
            "input": "25 + 37",
            "output": "25 + 37 = 62"
        },
        {
            "instruction": "å†™ä¸€é¦–å…³äºæ˜¥å¤©çš„è¯—",
            "input": "",
            "output": "æ˜¥é£è½»æŠšç»¿æŸ³æ¡ï¼Œ\nèŠ±å¼€æ»¡æ ‘é¸Ÿå„¿å«ã€‚\nè´è¶é£èˆè‰é’é’ï¼Œ\nç”Ÿæœºç›ç„¶æ˜¥æ„é—¹ã€‚"
        }
    ]
    
    os.makedirs("./data", exist_ok=True)
    with open("./data/sample_data.json", "w", encoding="utf-8") as f:
        json.dump(sample_data, f, ensure_ascii=False, indent=2)
    
    print("ğŸ“„ ç¤ºä¾‹æ•°æ®å·²åˆ›å»º: ./data/sample_data.json")

def main():
    parser = argparse.ArgumentParser(description="LoRAå¾®è°ƒè„šæœ¬")
    
    # æ¨¡å‹å‚æ•°
    parser.add_argument("--model_name_or_path", type=str, default="baichuan-inc/Baichuan2-7B-Chat")
    parser.add_argument("--cache_dir", type=str, default=None)
    parser.add_argument("--trust_remote_code", action="store_true", default=True)
    
    # æ•°æ®å‚æ•°
    parser.add_argument("--dataset_path", type=str, default="./data/sample_data.json")
    parser.add_argument("--validation_split_percentage", type=int, default=5)
    parser.add_argument("--max_train_samples", type=int, default=None)
    
    # LoRAå‚æ•°
    parser.add_argument("--lora_rank", type=int, default=8)
    parser.add_argument("--lora_alpha", type=int, default=16)
    parser.add_argument("--lora_dropout", type=float, default=0.1)
    parser.add_argument("--lora_target_modules", type=str, default="q_proj,v_proj")
    
    # é‡åŒ–å‚æ•°
    parser.add_argument("--use_4bit", action="store_true", default=True)
    parser.add_argument("--bnb_4bit_compute_dtype", type=str, default="float16")
    
    # è®­ç»ƒå‚æ•°
    parser.add_argument("--output_dir", type=str, default="./lora_output")
    parser.add_argument("--num_train_epochs", type=int, default=3)
    parser.add_argument("--per_device_train_batch_size", type=int, default=4)
    parser.add_argument("--gradient_accumulation_steps", type=int, default=4)
    parser.add_argument("--learning_rate", type=float, default=1e-4)
    parser.add_argument("--weight_decay", type=float, default=0.01)
    parser.add_argument("--warmup_steps", type=int, default=100)
    parser.add_argument("--logging_steps", type=int, default=10)
    parser.add_argument("--save_steps", type=int, default=500)
    parser.add_argument("--eval_steps", type=int, default=500)
    parser.add_argument("--fp16", action="store_true", default=True)
    parser.add_argument("--do_train", action="store_true", default=True)
    parser.add_argument("--do_eval", action="store_true", default=True)
    parser.add_argument("--create_sample_data", action="store_true", help="åˆ›å»ºç¤ºä¾‹æ•°æ®")
    
    args = parser.parse_args()
    
    # åˆ›å»ºç¤ºä¾‹æ•°æ®
    if args.create_sample_data:
        create_sample_data()
        return
    
    # åˆ›å»ºå‚æ•°å¯¹è±¡
    model_args = ModelArguments(
        model_name_or_path=args.model_name_or_path,
        cache_dir=args.cache_dir,
        trust_remote_code=args.trust_remote_code
    )
    
    data_args = DataArguments(
        dataset_path=args.dataset_path,
        validation_split_percentage=args.validation_split_percentage,
        max_train_samples=args.max_train_samples
    )
    
    lora_args = LoRAArguments(
        lora_rank=args.lora_rank,
        lora_alpha=args.lora_alpha,
        lora_dropout=args.lora_dropout,
        lora_target_modules=args.lora_target_modules
    )
    
    quant_args = QuantizationArguments(
        use_4bit=args.use_4bit,
        bnb_4bit_compute_dtype=args.bnb_4bit_compute_dtype
    )
    
    training_args = TrainingArguments(
        output_dir=args.output_dir,
        num_train_epochs=args.num_train_epochs,
        per_device_train_batch_size=args.per_device_train_batch_size,
        gradient_accumulation_steps=args.gradient_accumulation_steps,
        learning_rate=args.learning_rate,
        weight_decay=args.weight_decay,
        warmup_steps=args.warmup_steps,
        logging_steps=args.logging_steps,
        save_steps=args.save_steps,
        eval_steps=args.eval_steps,
        fp16=args.fp16,
        do_train=args.do_train,
        do_eval=args.do_eval,
        evaluation_strategy="steps" if args.do_eval else "no",
        save_strategy="steps",
        load_best_model_at_end=True,
        metric_for_best_model="eval_loss",
        greater_is_better=False,
        report_to="none"
    )
    
    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = LoRATrainer(model_args, data_args, training_args, lora_args, quant_args)
    
    # åŠ è½½ç»„ä»¶
    trainer.load_tokenizer()
    trainer.load_model()
    trainer.setup_lora()
    trainer.load_dataset()
    
    # å¼€å§‹è®­ç»ƒ
    trainer.train()
    
    # ä¿å­˜LoRAæ¨¡å‹
    trainer.save_lora_model(args.output_dir)

if __name__ == "__main__":
    main() 