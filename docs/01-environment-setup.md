# ğŸš€ DCUç¯å¢ƒæ­å»ºæŒ‡å—

æœ¬æŒ‡å—å°†å¸®åŠ©æ‚¨ä»é›¶å¼€å§‹æ­å»ºå®Œæ•´çš„æµ·å…‰DCUå¼€å‘ç¯å¢ƒï¼ŒåŒ…æ‹¬ç¡¬ä»¶æ£€æŸ¥ã€é©±åŠ¨å®‰è£…ã€å¼€å‘ç¯å¢ƒé…ç½®ç­‰ã€‚

## ğŸ“‹ ç¯å¢ƒè¦æ±‚

### ç¡¬ä»¶è¦æ±‚

| ç»„ä»¶ | æœ€ä½è¦æ±‚ | æ¨èé…ç½® | è¯´æ˜ |
|------|----------|----------|------|
| **DCUè®¾å¤‡** | Z100/K100 | Z100L/K100-AI | æµ·å…‰DCUåŠ é€Ÿå¡ |
| **CPU** | 8æ ¸å¿ƒ | 16æ ¸å¿ƒ+ | x86_64æ¶æ„ |
| **å†…å­˜** | 32GB | 128GB+ | DDR4/DDR5 |
| **å­˜å‚¨** | 500GB SSD | 2TB+ NVMe | é«˜é€Ÿå­˜å‚¨ |
| **ç½‘ç»œ** | åƒå…†ç½‘å¡ | ä¸‡å…†ç½‘å¡ | åˆ†å¸ƒå¼è®­ç»ƒéœ€è¦ |

### è½¯ä»¶è¦æ±‚

| è½¯ä»¶ | ç‰ˆæœ¬è¦æ±‚ | æ¨èç‰ˆæœ¬ | ç”¨é€” |
|------|----------|----------|------|
| **æ“ä½œç³»ç»Ÿ** | Ubuntu 20.04+ | Ubuntu 22.04 LTS | ä¸»æ“ä½œç³»ç»Ÿ |
| **Python** | 3.8+ | 3.10+ | å¼€å‘è¯­è¨€ |
| **DCU Runtime** | 5.0+ | æœ€æ–°ç‰ˆæœ¬ | DCUé©±åŠ¨ |
| **Docker** | 20.10+ | æœ€æ–°ç‰ˆæœ¬ | å®¹å™¨åŒ– |

## ğŸ”§ å®‰è£…æ­¥éª¤

### Step 1: ç³»ç»Ÿå‡†å¤‡

```bash
# æ›´æ–°ç³»ç»Ÿ
sudo apt update && sudo apt upgrade -y

# å®‰è£…åŸºç¡€å·¥å…·
sudo apt install -y \
    curl \
    wget \
    git \
    vim \
    htop \
    build-essential \
    cmake \
    pkg-config

# æ£€æŸ¥ç³»ç»Ÿä¿¡æ¯
uname -a
lscpu
free -h
df -h
```

### Step 2: DCUç¡¬ä»¶æ£€æŸ¥

```bash
# æ£€æŸ¥DCUè®¾å¤‡
lspci | grep -i display

# æ£€æŸ¥DCUè®¾å¤‡èŠ‚ç‚¹
ls -la /dev/kfd /dev/dri/

# æ£€æŸ¥DCUé©±åŠ¨çŠ¶æ€
dmesg | grep -i dcu
```

### Step 3: DCUé©±åŠ¨å®‰è£…

#### æ–¹æ³•1: ä½¿ç”¨å®˜æ–¹å®‰è£…åŒ…

```bash
# ä¸‹è½½DCUé©±åŠ¨åŒ…ï¼ˆè¯·ä»å®˜æ–¹è·å–æœ€æ–°ç‰ˆæœ¬ï¼‰
wget https://developer.sourcefind.cn/downloads/dcu-runtime-5.0.tar.gz

# è§£å‹å®‰è£…åŒ…
tar -xzf dcu-runtime-5.0.tar.gz
cd dcu-runtime-5.0

# å®‰è£…é©±åŠ¨
sudo ./install.sh

# é‡å¯ç³»ç»Ÿ
sudo reboot
```

#### æ–¹æ³•2: ä½¿ç”¨Dockeré•œåƒï¼ˆæ¨èï¼‰

```bash
# æ‹‰å–å®˜æ–¹DCUé•œåƒ
docker pull image.sourcefind.cn:5000/dcu/admin/base/pytorch:2.4.1-ubuntu22.04-dtk25.04-py3.10

# è¿è¡Œå®¹å™¨æµ‹è¯•
docker run --rm --device=/dev/kfd --device=/dev/dri \
    image.sourcefind.cn:5000/dcu/admin/base/pytorch:2.4.1-ubuntu22.04-dtk25.04-py3.10\
    python -c "import torch; print(torch.cuda.is_available())"
```

### Step 4: Pythonç¯å¢ƒé…ç½®

```bash
# å®‰è£…Python 3.10
sudo apt install -y python3.10 python3.10-venv python3.10-dev

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python3.10 -m venv dcu-env
source dcu-env/bin/activate

# å‡çº§pip
pip install --upgrade pip setuptools wheel
```

### Step 5: é¡¹ç›®å®‰è£…

```bash
# å…‹éš†é¡¹ç›®
git clone https://github.com/your-org/dcu-in-action.git
cd dcu-in-action

# å®‰è£…ä¾èµ–
pip install -r requirements.txt

# å®‰è£…é¡¹ç›®
pip install -e .

# é…ç½®ç¯å¢ƒå˜é‡
echo 'export DCU_VISIBLE_DEVICES=0,1,2,3' >> ~/.bashrc
echo 'export PYTHONPATH=$PWD:$PYTHONPATH' >> ~/.bashrc
source ~/.bashrc
```

## âœ… ç¯å¢ƒéªŒè¯

### åŸºç¡€éªŒè¯

```bash
# è¿è¡Œç¯å¢ƒæ£€æŸ¥è„šæœ¬
./common/setup/check_environment.sh

# éªŒè¯DCUè®¾å¤‡
python -c "
from common.dcu import device_manager
print('DCUè®¾å¤‡ä¿¡æ¯:')
print(device_manager.get_device_info())
"

# éªŒè¯PyTorch DCUæ”¯æŒ
python -c "
import torch
print(f'PyTorchç‰ˆæœ¬: {torch.__version__}')
print(f'DCUå¯ç”¨: {torch.cuda.is_available()}')
print(f'DCUè®¾å¤‡æ•°é‡: {torch.cuda.device_count()}')
"
```

### æ€§èƒ½æµ‹è¯•

```bash
# è¿è¡ŒåŸºç¡€æ€§èƒ½æµ‹è¯•
cd examples/benchmarks
python dcu_benchmark.py

# è¿è¡ŒçŸ©é˜µè®¡ç®—æµ‹è¯•
python matrix_benchmark.py --size 1024

# è¿è¡Œå†…å­˜æµ‹è¯•
python memory_benchmark.py
```

## ğŸ³ Dockerç¯å¢ƒï¼ˆæ¨èï¼‰

### æ„å»ºå¼€å‘é•œåƒ

```bash
# æ„å»ºé•œåƒ
docker build -t dcu-in-action:dev .

# è¿è¡Œå¼€å‘å®¹å™¨
docker run -it --rm \
    --device=/dev/kfd \
    --device=/dev/dri \
    -v $(pwd):/workspace \
    -p 8888:8888 \
    -p 6006:6006 \
    dcu-in-action:dev
```

### ä½¿ç”¨Docker Compose

```bash
# å¯åŠ¨å®Œæ•´å¼€å‘ç¯å¢ƒ
docker-compose up -d

# è¿›å…¥å¼€å‘å®¹å™¨
docker-compose exec dcu-dev bash

# æŸ¥çœ‹æœåŠ¡çŠ¶æ€
docker-compose ps
```

## ğŸ”§ å¸¸è§é—®é¢˜

### Q1: DCUè®¾å¤‡æœªæ£€æµ‹åˆ°

**é—®é¢˜**: `torch.cuda.is_available()` è¿”å› `False`

**è§£å†³æ–¹æ¡ˆ**:
```bash
# æ£€æŸ¥è®¾å¤‡æƒé™
ls -la /dev/kfd /dev/dri/

# æ·»åŠ ç”¨æˆ·åˆ°renderç»„
sudo usermod -a -G render $USER

# é‡æ–°ç™»å½•æˆ–é‡å¯
```

### Q2: å†…å­˜ä¸è¶³é”™è¯¯

**é—®é¢˜**: è®­ç»ƒæ—¶å‡ºç° `CUDA out of memory`

**è§£å†³æ–¹æ¡ˆ**:
```bash
# æ£€æŸ¥DCUå†…å­˜ä½¿ç”¨
python -c "
import torch
print(f'DCUå†…å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB')
print(f'å·²ç”¨å†…å­˜: {torch.cuda.memory_allocated(0) / 1024**3:.1f} GB')
"

# ä½¿ç”¨å†…å­˜ä¼˜åŒ–å·¥å…·
python common/dcu/memory_optimizer.py --optimize
```

### Q3: æ€§èƒ½ä¸ä½³

**é—®é¢˜**: è®­ç»ƒé€Ÿåº¦æ…¢äºé¢„æœŸ

**è§£å†³æ–¹æ¡ˆ**:
```bash
# è¿è¡Œæ€§èƒ½åˆ†æ
python common/dcu/performance_profiler.py --profile

# æ£€æŸ¥DCUåˆ©ç”¨ç‡
watch -n 1 'python -c "
import torch
for i in range(torch.cuda.device_count()):
    print(f\"DCU {i}: {torch.cuda.utilization(i)}%\")
"'
```

## ğŸ“Š æ€§èƒ½åŸºå‡†

### ç¡¬ä»¶æ€§èƒ½

| æµ‹è¯•é¡¹ç›® | Z100 | K100 | K100-AI |
|----------|------|------|---------|
| **è®¡ç®—æ€§èƒ½** | 32 TFLOPS | 45 TFLOPS | 60 TFLOPS |
| **å†…å­˜å¸¦å®½** | 1.6 TB/s | 2.0 TB/s | 2.4 TB/s |
| **æ˜¾å­˜å®¹é‡** | 32GB | 32GB | 64GB |

### è½¯ä»¶æ€§èƒ½

| æ¡†æ¶ | ç‰ˆæœ¬ | æ€§èƒ½æå‡ | å…¼å®¹æ€§ |
|------|------|----------|--------|
| **PyTorch** | 2.0+ | 3-5x | âœ… å®Œå…¨å…¼å®¹ |
| **Transformers** | 4.30+ | 2-4x | âœ… å®Œå…¨å…¼å®¹ |
| **vLLM** | 0.2.0+ | 5-10x | âœ… å®Œå…¨å…¼å®¹ |

## ğŸš€ ä¸‹ä¸€æ­¥

ç¯å¢ƒæ­å»ºå®Œæˆåï¼Œæ‚¨å¯ä»¥ï¼š

1. **å­¦ä¹ åŸºç¡€æ•™ç¨‹**: [ç¬¬ä¸€ä¸ªDCUç¨‹åº](02-first-dcu-program.md)
2. **è¿è¡Œè®­ç»ƒç¤ºä¾‹**: [å¤§æ¨¡å‹è®­ç»ƒå®æˆ˜](02-model-training.md)
3. **å°è¯•æ¨¡å‹å¾®è°ƒ**: [é«˜æ•ˆæ¨¡å‹å¾®è°ƒ](03-model-finetuning.md)
4. **éƒ¨ç½²æ¨ç†æœåŠ¡**: [æ¨ç†æœåŠ¡éƒ¨ç½²](04-model-inference.md)

## ğŸ“ è·å–å¸®åŠ©

å¦‚æœåœ¨ç¯å¢ƒæ­å»ºè¿‡ç¨‹ä¸­é‡åˆ°é—®é¢˜ï¼š

- ğŸ“š æŸ¥çœ‹ [FAQæ–‡æ¡£](../faq.md)
- ğŸ› æäº¤ [GitHub Issue](https://github.com/your-org/dcu-in-action/issues)
- ğŸ’¬ åŠ å…¥ [æŠ€æœ¯äº¤æµç¾¤](https://discord.gg/dcu-in-action)
- ğŸ“§ å‘é€é‚®ä»¶åˆ° [support@dcu-in-action.org](mailto:support@dcu-in-action.org) 